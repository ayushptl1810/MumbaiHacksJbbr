2025-11-28 02:32:19,277 [INFO] __main__: Orchestrator Agent initialized with Google Agents SDK - Session: orchestrator_session_20251128_023219
2025-11-28 02:32:19,277 [INFO] __main__: Initializing Google Agents Orchestrator...
2025-11-28 02:32:19,278 [INFO] __main__: Google Agents Orchestrator initialized successfully
2025-11-28 02:32:19,278 [INFO] __main__: Initializing Claim Verifier with Google Agents...
2025-11-28 02:32:19,278 [INFO] claim_verifier.agents: Google Agents Orchestrator initialized successfully
2025-11-28 02:32:19,278 [INFO] claim_verifier.agents: Created Google Agent: claim_extractor - Claim Extraction Specialist
2025-11-28 02:32:19,280 [INFO] claim_verifier.agents: Created Google Agent: fact_verifier - Fact Verification Specialist
2025-11-28 02:32:19,280 [INFO] claim_verifier.agents: Created Google Agent: priority_assessor - Priority Assessment Specialist
2025-11-28 02:32:19,280 [INFO] claim_verifier.agents: Created Google Agent: report_generator - Report Generation Specialist
2025-11-28 02:32:19,280 [INFO] claim_verifier.agents: Claim verification agents setup completed with Google Agents SDK
2025-11-28 02:32:19,280 [INFO] claim_verifier.agents: Claim Verifier Orchestrator initialized with Google Agents SDK
2025-11-28 02:32:19,280 [INFO] __main__: Initializing Explanation Agent with Google Agents...
2025-11-28 02:32:19,280 [INFO] explanation_agent.agents: Google Agents Orchestrator initialized for Explanation Agent
2025-11-28 02:32:19,280 [INFO] explanation_agent.agents: Created Google Agent: content_generator - Content Generation Specialist
2025-11-28 02:32:19,281 [INFO] explanation_agent.agents: Created Google Agent: source_analyzer - Source Analysis Specialist
2025-11-28 02:32:19,281 [INFO] explanation_agent.agents: Created Google Agent: post_formatter - Post Formatting Specialist
2025-11-28 02:32:19,281 [INFO] explanation_agent.agents: Google Agents setup completed for explanation workflow
2025-11-28 02:32:19,281 [INFO] explanation_agent.agents: Explanation Agent initialized with Google Agents SDK
2025-11-28 02:32:19,281 [INFO] __main__: Created Google Agent: trend_scanner - Trend Scanning Coordinator
2025-11-28 02:32:19,281 [INFO] __main__: Created Google Agent: verifier_coordinator - Claim Verification Coordinator
2025-11-28 02:32:19,281 [INFO] __main__: Created Google Agent: explanation_coordinator - Explanation Generation Coordinator
2025-11-28 02:32:19,281 [INFO] __main__: Created Google Agent: results_integrator - Results Integration Specialist
2025-11-28 02:32:19,281 [INFO] __main__: Orchestrator agents setup completed with Google Agents SDK
2025-11-28 02:32:19,281 [INFO] __main__: Orchestrator Agent fully initialized with Google Agents SDK
2025-11-28 02:32:19,282 [INFO] __main__: Starting Google Agents orchestrated pipeline: Trend Scanning → Claim Verification
2025-11-28 02:32:19,282 [INFO] __main__: Step 1: Executing trend scanning with Google Agents...
2025-11-28 02:32:19,282 [INFO] __main__: Starting Google Agents workflow with 1 tasks
2025-11-28 02:32:19,282 [INFO] __main__: Executing task 1/1: trend_scanner - Execute comprehensive Reddit trend scanning with AI summarization and claim extraction
2025-11-28 02:32:19,282 [INFO] __main__: Agent Trend Scanning Coordinator has 1 tools available
2025-11-28 02:32:19,282 [INFO] __main__: Tool 0: <class 'function'> with methods: []...
2025-11-28 02:32:19,283 [INFO] __main__: Starting tool detection for task: 'Execute comprehensive Reddit trend scanning with AI summarization and claim extraction'
2025-11-28 02:32:19,283 [INFO] __main__: Checking conditions:
2025-11-28 02:32:19,283 [INFO] __main__:   - hasattr(tool, '__call__'): True
2025-11-28 02:32:19,283 [INFO] __main__:   - 'scan' in task_description.lower(): True
2025-11-28 02:32:19,283 [INFO] __main__:   - hasattr(tool, 'verify_content'): False
2025-11-28 02:32:19,283 [INFO] __main__:   - 'verify' in task_description.lower(): False
2025-11-28 02:32:19,283 [INFO] __main__:   - hasattr(tool, 'execute_workflow'): False
2025-11-28 02:32:19,283 [INFO] __main__:   - hasattr(tool, 'batch_create_posts'): False
2025-11-28 02:32:19,283 [INFO] __main__:   - 'explanation' in task_description.lower(): False
2025-11-28 02:32:19,284 [INFO] __main__:   - hasattr(tool, 'create_debunk_post'): False
2025-11-28 02:32:19,284 [INFO] __main__: Agent Trend Scanning Coordinator executing trend scanning tool...
2025-11-28 02:32:19,285 [INFO] trend_scanner.google_agents: Google Agents orchestration initialized successfully
2025-11-28 02:32:19,367 [INFO] trend_scanner.google_agents: PRAW Reddit client authenticated successfully
2025-11-28 02:32:22,488 [INFO] trend_scanner.tools.reddit_scan_tool: Google Agents SDK initialized successfully
2025-11-28 02:32:22,489 [INFO] trend_scanner.tools.twitter_scan_tool: Google Agents SDK initialized for Twitter scanner
2025-11-28 02:32:22,489 [INFO] trend_scanner.google_agents: Twitter scanner initialized successfully
2025-11-28 02:32:22,490 [INFO] trend_scanner.google_agents: Created Google Agent: reddit_scanner - Enhanced Reddit Trend Scout
2025-11-28 02:32:22,490 [INFO] trend_scanner.google_agents: Created Google Agent: twitter_scanner - Twitter/X Trend Scout
2025-11-28 02:32:22,490 [INFO] trend_scanner.google_agents: Created Google Agent: risk_assessor - Cross-Platform Content Risk Assessor
2025-11-28 02:32:22,490 [INFO] trend_scanner.google_agents: Google agents created for platforms: Reddit, Twitter
2025-11-28 02:32:22,490 [INFO] trend_scanner.google_agents: Target subreddits configured: []
2025-11-28 02:32:22,490 [INFO] trend_scanner.google_agents: Target Twitter configured: 8 accounts, AUTO-DISCOVER trending topics, scan_type=trending
2025-11-28 02:32:22,490 [INFO] trend_scanner.google_agents: Starting multi-platform trend scanning (Twitter/trending)...
2025-11-28 02:32:22,490 [INFO] trend_scanner.google_agents: Created Google Agent: reddit_scanner - Reddit Trend Scout
2025-11-28 02:32:22,491 [INFO] trend_scanner.google_agents: Created Google Agent: twitter_scanner - Twitter/X Trend Scout
2025-11-28 02:32:22,491 [INFO] trend_scanner.google_agents: Created Google Agent: risk_assessor - Cross-Platform Content Risk Assessor
2025-11-28 02:32:22,491 [INFO] trend_scanner.google_agents: Auto-discovering Twitter trending topics...
2025-11-28 02:32:23,080 [INFO] trend_scanner.tools.twitter_scan_tool: Loading cookies from twitter_cookies.json
2025-11-28 02:32:23,080 [INFO] trend_scanner.tools.twitter_scan_tool: Twitter client authenticated from cookies
2025-11-28 02:32:23,080 [INFO] trend_scanner.tools.twitter_scan_tool: Fetching Twitter trending topics...
2025-11-28 02:32:24,547 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Thanksgiving
2025-11-28 02:32:24,550 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: #StrangerThings5
2025-11-28 02:32:24,550 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: #HBDUdhay
2025-11-28 02:32:24,550 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: #WPLAuction
2025-11-28 02:32:24,550 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: #चतुर्थ_श्रेणी_पद_70K_करो
2025-11-28 02:32:24,550 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: #RapidoRide
2025-11-28 02:32:24,550 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: AUKAAT KE BAHAR TRAILER OUT
2025-11-28 02:32:24,550 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: BB19 ASHNOOR CENTRIC SHOW
2025-11-28 02:32:24,550 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Hindu Sanskriti
2025-11-28 02:32:24,550 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: UP Warriorz
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: हरिवंश राय बच्चन
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: A. 5000mAh
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: I VOTED FOR SHEHBAAZ
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Deepti Sharma
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: B. Panda Glass
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: byers
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Lauren Bell
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: DYTD TRAILER
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: संतोष वर्मा
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: इमरान खान
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Ranchi
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: B. 33W
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Gujarat Giants
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: B. 50MP
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Grace Harris
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: National Guard
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Alyssa Healy
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Meg Lanning
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: value education
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Puma
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Successfully fetched 30 trending topics
2025-11-28 02:32:24,551 [INFO] trend_scanner.google_agents: Auto-discovered 30 trending topics: ['Thanksgiving', '#StrangerThings5', '#HBDUdhay', '#WPLAuction', '#चतुर्थ_श्रेणी_पद_70K_करो', '#RapidoRide', 'AUKAAT KE BAHAR TRAILER OUT', 'BB19 ASHNOOR CENTRIC SHOW', 'Hindu Sanskriti', 'UP Warriorz', 'हरिवंश राय बच्चन', 'A. 5000mAh', 'I VOTED FOR SHEHBAAZ', 'Deepti Sharma', 'B. Panda Glass', 'byers', 'Lauren Bell', 'DYTD TRAILER', 'संतोष वर्मा', 'इमरान खान', 'Ranchi', 'B. 33W', 'Gujarat Giants', 'B. 50MP', 'Grace Harris', 'National Guard', 'Alyssa Healy', 'Meg Lanning', 'value education', 'Puma']
2025-11-28 02:32:24,551 [INFO] trend_scanner.google_agents: Starting parallel scan across 0 subreddits, 38 Twitter targets
2025-11-28 02:32:24,551 [INFO] trend_scanner.google_agents: Starting parallel workflow with 38 tasks
2025-11-28 02:32:24,551 [INFO] trend_scanner.google_agents: Executing parallel task 1/38 with agent 'twitter_scanner'
2025-11-28 02:32:24,551 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for elonmusk (type: trending)
2025-11-28 02:32:24,551 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=elonmusk, limit=50)
2025-11-28 02:32:24,929 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:32:24,929 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: elonmusk
2025-11-28 02:32:26,136 [WARNING] trend_scanner.tools.twitter_scan_tool: Twitter returned 404 Not Found for search 'elonmusk' - no results available
2025-11-28 02:32:26,136 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: elonmusk
2025-11-28 02:32:26,137 [INFO] trend_scanner.google_agents: Executing parallel task 2/38 with agent 'twitter_scanner'
2025-11-28 02:32:26,137 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for QudsNen (type: trending)
2025-11-28 02:32:26,138 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=QudsNen, limit=50)
2025-11-28 02:32:26,486 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:32:26,486 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: QudsNen
2025-11-28 02:32:28,133 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 11 tweets from search (limited to 50)
2025-11-28 02:32:28,135 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 2 tweets
2025-11-28 02:32:28,141 [INFO] LiteLLM: 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2025-11-28 02:32:38,236 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 02:32:38,238 [INFO] trend_scanner.tools.twitter_scan_tool: Batch risk assessment completed for 2 tweets
2025-11-28 02:32:38,239 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 2 tweets in 1 API call
2025-11-28 02:32:38,240 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned QudsNen (11 tweets, type=trending), scraped 0 links, found 2 trending tweets
2025-11-28 02:32:38,240 [INFO] trend_scanner.google_agents: Executing parallel task 3/38 with agent 'twitter_scanner'
2025-11-28 02:32:38,240 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for NupurSharmaBJP (type: trending)
2025-11-28 02:32:38,240 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=NupurSharmaBJP, limit=50)
2025-11-28 02:32:38,615 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:32:38,615 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: NupurSharmaBJP
2025-11-28 02:32:40,503 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 4 tweets from search (limited to 50)
2025-11-28 02:32:40,503 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 2 tweets
2025-11-28 02:32:40,503 [INFO] LiteLLM: 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2025-11-28 02:32:48,182 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 02:32:48,183 [INFO] trend_scanner.tools.twitter_scan_tool: Batch risk assessment completed for 2 tweets
2025-11-28 02:32:48,185 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 2 tweets in 1 API call
2025-11-28 02:32:48,185 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned NupurSharmaBJP (4 tweets, type=trending), scraped 0 links, found 2 trending tweets
2025-11-28 02:32:48,185 [INFO] trend_scanner.google_agents: Executing parallel task 4/38 with agent 'twitter_scanner'
2025-11-28 02:32:48,185 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for IndianGems_ (type: trending)
2025-11-28 02:32:48,187 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=IndianGems_, limit=50)
2025-11-28 02:32:48,748 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:32:48,748 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: IndianGems_
2025-11-28 02:32:50,346 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from search (limited to 50)
2025-11-28 02:32:50,346 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 02:32:50,346 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 02:32:50,346 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned IndianGems_ (20 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 02:32:50,348 [INFO] trend_scanner.google_agents: Executing parallel task 5/38 with agent 'twitter_scanner'
2025-11-28 02:32:50,348 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for WeDravidiansva_shiva (type: trending)
2025-11-28 02:32:50,350 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=WeDravidiansva_shiva, limit=50)
2025-11-28 02:32:50,831 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:32:50,832 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: WeDravidiansva_shiva
2025-11-28 02:32:52,055 [WARNING] trend_scanner.tools.twitter_scan_tool: Twitter returned 404 Not Found for search 'WeDravidiansva_shiva' - no results available
2025-11-28 02:32:52,056 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: WeDravidiansva_shiva
2025-11-28 02:32:52,056 [INFO] trend_scanner.google_agents: Executing parallel task 6/38 with agent 'twitter_scanner'
2025-11-28 02:32:52,057 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Gurudev (type: trending)
2025-11-28 02:32:52,057 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Gurudev, limit=50)
2025-11-28 02:32:52,551 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:32:52,551 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Gurudev
2025-11-28 02:32:53,920 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 12 tweets from search (limited to 50)
2025-11-28 02:32:53,921 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 6 tweets
2025-11-28 02:32:53,922 [INFO] LiteLLM: 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2025-11-28 02:33:06,105 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 02:33:06,106 [INFO] trend_scanner.tools.twitter_scan_tool: Batch risk assessment completed for 6 tweets
2025-11-28 02:33:06,108 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 6 tweets in 1 API call
2025-11-28 02:33:06,108 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned Gurudev (12 tweets, type=trending), scraped 0 links, found 5 trending tweets
2025-11-28 02:33:06,109 [INFO] trend_scanner.google_agents: Executing parallel task 7/38 with agent 'twitter_scanner'
2025-11-28 02:33:06,109 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for PypAyurveddhruv_rathee (type: trending)
2025-11-28 02:33:06,110 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=PypAyurveddhruv_rathee, limit=50)
2025-11-28 02:33:06,599 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:33:06,600 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: PypAyurveddhruv_rathee
2025-11-28 02:33:07,714 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 0 tweets from search (limited to 50)
2025-11-28 02:33:07,714 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: PypAyurveddhruv_rathee
2025-11-28 02:33:07,715 [INFO] trend_scanner.google_agents: Executing parallel task 8/38 with agent 'twitter_scanner'
2025-11-28 02:33:07,715 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for MAGANationX (type: trending)
2025-11-28 02:33:07,716 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=MAGANationX, limit=50)
2025-11-28 02:33:08,194 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:33:08,194 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: MAGANationX
2025-11-28 02:33:09,430 [WARNING] trend_scanner.tools.twitter_scan_tool: Twitter returned 404 Not Found for search 'MAGANationX' - no results available
2025-11-28 02:33:09,430 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: MAGANationX
2025-11-28 02:33:09,430 [INFO] trend_scanner.google_agents: Executing parallel task 9/38 with agent 'twitter_scanner'
2025-11-28 02:33:09,430 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Thanksgiving (type: trending)
2025-11-28 02:33:09,434 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Thanksgiving, limit=50)
2025-11-28 02:33:09,792 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:33:09,792 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Thanksgiving
2025-11-28 02:33:11,367 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 18 tweets from search (limited to 50)
2025-11-28 02:33:11,367 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 02:33:11,369 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 02:33:11,369 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned Thanksgiving (18 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 02:33:11,369 [INFO] trend_scanner.google_agents: Executing parallel task 10/38 with agent 'twitter_scanner'
2025-11-28 02:33:11,369 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for #StrangerThings5 (type: trending)
2025-11-28 02:33:11,370 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=#StrangerThings5, limit=50)
2025-11-28 02:33:11,706 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:33:11,706 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: #StrangerThings5
2025-11-28 02:33:13,434 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from search (limited to 50)
2025-11-28 02:33:13,434 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 02:33:13,435 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 02:33:13,435 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned #StrangerThings5 (20 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 02:33:13,435 [INFO] trend_scanner.google_agents: Executing parallel task 11/38 with agent 'twitter_scanner'
2025-11-28 02:33:13,435 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for #HBDUdhay (type: trending)
2025-11-28 02:33:13,436 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=#HBDUdhay, limit=50)
2025-11-28 02:33:13,794 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:33:13,794 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: #HBDUdhay
2025-11-28 02:33:15,309 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 4 tweets from search (limited to 50)
2025-11-28 02:33:15,309 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 02:33:15,310 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 02:33:15,310 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned #HBDUdhay (4 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 02:33:15,310 [INFO] trend_scanner.google_agents: Executing parallel task 12/38 with agent 'twitter_scanner'
2025-11-28 02:33:15,310 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for #WPLAuction (type: trending)
2025-11-28 02:33:15,311 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=#WPLAuction, limit=50)
2025-11-28 02:33:15,670 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:33:15,670 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: #WPLAuction
2025-11-28 02:33:17,039 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 18 tweets from search (limited to 50)
2025-11-28 02:33:17,041 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 1 tweets
2025-11-28 02:33:17,041 [INFO] LiteLLM: 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2025-11-28 02:33:21,831 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 02:33:21,831 [INFO] trend_scanner.tools.twitter_scan_tool: Batch risk assessment completed for 1 tweets
2025-11-28 02:33:21,831 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 1 tweets in 1 API call
2025-11-28 02:33:21,831 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned #WPLAuction (18 tweets, type=trending), scraped 0 links, found 1 trending tweets
2025-11-28 02:33:21,835 [INFO] trend_scanner.google_agents: Executing parallel task 13/38 with agent 'twitter_scanner'
2025-11-28 02:33:21,835 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for #चतुर्थ_श्रेणी_पद_70K_करो (type: trending)
2025-11-28 02:33:21,835 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=#चतुर्थ_श्रेणी_पद_70K_करो, limit=50)
2025-11-28 02:33:22,183 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:33:22,183 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: #चतुर्थ_श्रेणी_पद_70K_करो
2025-11-28 02:33:24,319 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 19 tweets from search (limited to 50)
2025-11-28 02:33:24,322 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 12 tweets
2025-11-28 02:33:24,323 [INFO] LiteLLM: 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2025-11-28 02:33:33,906 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 02:33:33,906 [INFO] trend_scanner.tools.twitter_scan_tool: Batch risk assessment completed for 12 tweets
2025-11-28 02:33:33,908 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 12 tweets in 1 API call
2025-11-28 02:33:33,908 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned #चतुर्थ_श्रेणी_पद_70K_करो (19 tweets, type=trending), scraped 0 links, found 12 trending tweets
2025-11-28 02:33:33,908 [INFO] trend_scanner.google_agents: Executing parallel task 14/38 with agent 'twitter_scanner'
2025-11-28 02:33:33,908 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for #RapidoRide (type: trending)
2025-11-28 02:33:33,908 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=#RapidoRide, limit=50)
2025-11-28 02:33:34,245 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:33:34,245 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: #RapidoRide
2025-11-28 02:33:35,233 [WARNING] trend_scanner.tools.twitter_scan_tool: Twitter returned 404 Not Found for search '#RapidoRide' - no results available
2025-11-28 02:33:35,233 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: #RapidoRide
2025-11-28 02:33:35,233 [INFO] trend_scanner.google_agents: Executing parallel task 15/38 with agent 'twitter_scanner'
2025-11-28 02:33:35,233 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for AUKAAT KE BAHAR TRAILER OUT (type: trending)
2025-11-28 02:33:35,236 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=AUKAAT KE BAHAR TRAILER OUT, limit=50)
2025-11-28 02:33:35,601 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:33:35,601 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: AUKAAT KE BAHAR TRAILER OUT
2025-11-28 02:33:37,725 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from search (limited to 50)
2025-11-28 02:33:37,730 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 18 tweets
2025-11-28 02:33:37,730 [INFO] LiteLLM: 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2025-11-28 02:33:49,817 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 02:33:49,818 [INFO] trend_scanner.tools.twitter_scan_tool: Batch risk assessment completed for 18 tweets
2025-11-28 02:33:49,821 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 18 tweets in 1 API call
2025-11-28 02:33:49,821 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned AUKAAT KE BAHAR TRAILER OUT (20 tweets, type=trending), scraped 0 links, found 17 trending tweets
2025-11-28 02:33:49,822 [INFO] trend_scanner.google_agents: Executing parallel task 16/38 with agent 'twitter_scanner'
2025-11-28 02:33:49,822 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for BB19 ASHNOOR CENTRIC SHOW (type: trending)
2025-11-28 02:33:49,823 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=BB19 ASHNOOR CENTRIC SHOW, limit=50)
2025-11-28 02:33:50,269 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:33:50,269 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: BB19 ASHNOOR CENTRIC SHOW
2025-11-28 02:33:51,339 [WARNING] trend_scanner.tools.twitter_scan_tool: Twitter returned 404 Not Found for search 'BB19 ASHNOOR CENTRIC SHOW' - no results available
2025-11-28 02:33:51,339 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: BB19 ASHNOOR CENTRIC SHOW
2025-11-28 02:33:51,340 [INFO] trend_scanner.google_agents: Executing parallel task 17/38 with agent 'twitter_scanner'
2025-11-28 02:33:51,340 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Hindu Sanskriti (type: trending)
2025-11-28 02:33:51,341 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Hindu Sanskriti, limit=50)
2025-11-28 02:33:51,755 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:33:51,755 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Hindu Sanskriti
2025-11-28 02:33:53,606 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 10 tweets from search (limited to 50)
2025-11-28 02:33:53,606 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 6 tweets
2025-11-28 02:33:53,607 [INFO] LiteLLM: 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2025-11-28 02:34:06,436 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 02:34:06,436 [INFO] trend_scanner.tools.twitter_scan_tool: Batch risk assessment completed for 6 tweets
2025-11-28 02:34:06,437 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 6 tweets in 1 API call
2025-11-28 02:34:06,437 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned Hindu Sanskriti (10 tweets, type=trending), scraped 0 links, found 1 trending tweets
2025-11-28 02:34:06,438 [INFO] trend_scanner.google_agents: Executing parallel task 18/38 with agent 'twitter_scanner'
2025-11-28 02:34:06,438 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for UP Warriorz (type: trending)
2025-11-28 02:34:06,439 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=UP Warriorz, limit=50)
2025-11-28 02:34:06,879 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:06,879 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: UP Warriorz
2025-11-28 02:34:08,655 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from search (limited to 50)
2025-11-28 02:34:08,656 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 5 tweets
2025-11-28 02:34:08,657 [INFO] LiteLLM: 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2025-11-28 02:34:19,255 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 02:34:19,256 [INFO] trend_scanner.tools.twitter_scan_tool: Batch risk assessment completed for 5 tweets
2025-11-28 02:34:19,257 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 5 tweets in 1 API call
2025-11-28 02:34:19,257 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned UP Warriorz (20 tweets, type=trending), scraped 0 links, found 5 trending tweets
2025-11-28 02:34:19,258 [INFO] trend_scanner.google_agents: Executing parallel task 19/38 with agent 'twitter_scanner'
2025-11-28 02:34:19,259 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for हरिवंश राय बच्चन (type: trending)
2025-11-28 02:34:19,259 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=हरिवंश राय बच्चन, limit=50)
2025-11-28 02:34:19,704 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:19,704 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: हरिवंश राय बच्चन
2025-11-28 02:34:21,041 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:21,043 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:21,045 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: हरिवंश राय बच्चन
2025-11-28 02:34:21,045 [INFO] trSend_scanner.google_agents: Executing parallel task 20/38 with agent 'twitter_scanner'
2025-11-28 02:34:21,045 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for A. 5000mAh (type: trending)
2025-11-28 02:34:21,046 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=A. 5000mAh, limit=50)
2025-11-28 02:34:21,473 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:21,473 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: A. 5000mAh
2025-11-28 02:34:23,128 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:23,128 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:23,128 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: A. 5000mAh
2025-11-28 02:34:23,130 [INFO] trend_scanner.google_agents: Executing parallel task 21/38 with agent 'twitter_scanner'
2025-11-28 02:34:23,130 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for I VOTED FOR SHEHBAAZ (type: trending)
2025-11-28 02:34:23,130 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=I VOTED FOR SHEHBAAZ, limit=50)
2025-11-28 02:34:23,584 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:23,584 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: I VOTED FOR SHEHBAAZ
2025-11-28 02:34:25,092 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:25,093 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:25,093 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: I VOTED FOR SHEHBAAZ
2025-11-28 02:34:25,093 [INFO] trend_scanner.google_agents: Executing parallel task 22/38 with agent 'twitter_scanner'
2025-11-28 02:34:25,093 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Deepti Sharma (type: trending)
2025-11-28 02:34:25,094 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Deepti Sharma, limit=50)
2025-11-28 02:34:25,539 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:25,540 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Deepti Sharma
2025-11-28 02:34:27,210 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:27,211 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:27,211 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: Deepti Sharma
2025-11-28 02:34:27,212 [INFO] trend_scanner.google_agents: Executing parallel task 23/38 with agent 'twitter_scanner'
2025-11-28 02:34:27,212 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for B. Panda Glass (type: trending)
2025-11-28 02:34:27,213 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=B. Panda Glass, limit=50)
2025-11-28 02:34:27,639 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:27,640 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: B. Panda Glass
2025-11-28 02:34:29,665 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:29,666 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:29,666 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: B. Panda Glass
2025-11-28 02:34:29,666 [INFO] trend_scanner.google_agents: Executing parallel task 24/38 with agent 'twitter_scanner'
2025-11-28 02:34:29,666 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for byers (type: trending)
2025-11-28 02:34:29,667 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=byers, limit=50)
2025-11-28 02:34:30,101 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:30,101 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: byers
2025-11-28 02:34:31,730 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:31,732 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:31,732 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: byers
2025-11-28 02:34:31,732 [INFO] trend_scanner.google_agents: Executing parallel task 25/38 with agent 'twitter_scanner'
2025-11-28 02:34:31,732 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Lauren Bell (type: trending)
2025-11-28 02:34:31,734 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Lauren Bell, limit=50)
2025-11-28 02:34:32,146 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:32,147 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Lauren Bell
2025-11-28 02:34:33,734 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:33,735 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:33,735 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: Lauren Bell
2025-11-28 02:34:33,735 [INFO] trend_scanner.google_agents: Executing parallel task 26/38 with agent 'twitter_scanner'
2025-11-28 02:34:33,735 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for DYTD TRAILER (type: trending)
2025-11-28 02:34:33,737 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=DYTD TRAILER, limit=50)
2025-11-28 02:34:34,159 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:34,159 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: DYTD TRAILER
2025-11-28 02:34:35,486 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:35,487 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:35,487 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: DYTD TRAILER
2025-11-28 02:34:35,487 [INFO] trend_scanner.google_agents: Executing parallel task 27/38 with agent 'twitter_scanner'
2025-11-28 02:34:35,488 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for संतोष वर्मा (type: trending)
2025-11-28 02:34:35,488 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=संतोष वर्मा, limit=50)
2025-11-28 02:34:35,919 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:35,919 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: संतोष वर्मा
2025-11-28 02:34:37,354 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:37,355 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:37,355 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: संतोष वर्मा
2025-11-28 02:34:37,355 [INFO] trend_scanner.google_agents: Executing parallel task 28/38 with agent 'twitter_scanner'
2025-11-28 02:34:37,355 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for इमरान खान (type: trending)
2025-11-28 02:34:37,357 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=इमरान खान, limit=50)
2025-11-28 02:34:37,777 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:37,777 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: इमरान खान
2025-11-28 02:34:39,406 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:39,406 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:39,407 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: इमरान खान
2025-11-28 02:34:39,407 [INFO] trend_scanner.google_agents: Executing parallel task 29/38 with agent 'twitter_scanner'
2025-11-28 02:34:39,407 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Ranchi (type: trending)
2025-11-28 02:34:39,408 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Ranchi, limit=50)
2025-11-28 02:34:39,862 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:39,862 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Ranchi
2025-11-28 02:34:41,243 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:41,244 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:41,244 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: Ranchi
2025-11-28 02:34:41,244 [INFO] trend_scanner.google_agents: Executing parallel task 30/38 with agent 'twitter_scanner'
2025-11-28 02:34:41,244 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for B. 33W (type: trending)
2025-11-28 02:34:41,245 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=B. 33W, limit=50)
2025-11-28 02:34:41,695 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:41,695 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: B. 33W
2025-11-28 02:34:43,211 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:43,211 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:43,212 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: B. 33W
2025-11-28 02:34:43,213 [INFO] trend_scanner.google_agents: Executing parallel task 31/38 with agent 'twitter_scanner'
2025-11-28 02:34:43,213 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Gujarat Giants (type: trending)
2025-11-28 02:34:43,214 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Gujarat Giants, limit=50)
2025-11-28 02:34:43,616 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:43,616 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Gujarat Giants
2025-11-28 02:34:45,093 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:45,094 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:45,094 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: Gujarat Giants
2025-11-28 02:34:45,095 [INFO] trend_scanner.google_agents: Executing parallel task 32/38 with agent 'twitter_scanner'
2025-11-28 02:34:45,095 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for B. 50MP (type: trending)
2025-11-28 02:34:45,097 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=B. 50MP, limit=50)
2025-11-28 02:34:45,517 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:45,517 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: B. 50MP
2025-11-28 02:34:46,878 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:46,879 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:46,880 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: B. 50MP
2025-11-28 02:34:46,880 [INFO] trend_scanner.google_agents: Executing parallel task 33/38 with agent 'twitter_scanner'
2025-11-28 02:34:46,880 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Grace Harris (type: trending)
2025-11-28 02:34:46,881 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Grace Harris, limit=50)
2025-11-28 02:34:47,306 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:47,306 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Grace Harris
2025-11-28 02:34:49,257 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:49,258 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:49,258 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: Grace Harris
2025-11-28 02:34:49,259 [INFO] trend_scanner.google_agents: Executing parallel task 34/38 with agent 'twitter_scanner'
2025-11-28 02:34:49,259 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for National Guard (type: trending)
2025-11-28 02:34:49,260 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=National Guard, limit=50)
2025-11-28 02:34:49,704 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:49,704 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: National Guard
2025-11-28 02:34:51,346 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:51,347 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:51,347 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: National Guard
2025-11-28 02:34:51,347 [INFO] trend_scanner.google_agents: Executing parallel task 35/38 with agent 'twitter_scanner'
2025-11-28 02:34:51,348 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Alyssa Healy (type: trending)
2025-11-28 02:34:51,350 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Alyssa Healy, limit=50)
2025-11-28 02:34:51,766 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:51,766 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Alyssa Healy
2025-11-28 02:34:53,271 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:53,272 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:53,272 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: Alyssa Healy
2025-11-28 02:34:53,273 [INFO] trend_scanner.google_agents: Executing parallel task 36/38 with agent 'twitter_scanner'
2025-11-28 02:34:53,273 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Meg Lanning (type: trending)
2025-11-28 02:34:53,274 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Meg Lanning, limit=50)
2025-11-28 02:34:53,702 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:53,702 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Meg Lanning
2025-11-28 02:34:55,289 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:55,290 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:55,291 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: Meg Lanning
2025-11-28 02:34:55,291 [INFO] trend_scanner.google_agents: Executing parallel task 37/38 with agent 'twitter_scanner'
2025-11-28 02:34:55,291 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for value education (type: trending)
2025-11-28 02:34:55,292 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=value education, limit=50)
2025-11-28 02:34:55,706 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:55,707 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: value education
2025-11-28 02:34:57,054 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:57,055 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:57,055 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: value education
2025-11-28 02:34:57,055 [INFO] trend_scanner.google_agents: Executing parallel task 38/38 with agent 'twitter_scanner'
2025-11-28 02:34:57,056 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Puma (type: trending)
2025-11-28 02:34:57,056 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Puma, limit=50)
2025-11-28 02:34:57,483 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 02:34:57,483 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Puma
2025-11-28 02:34:59,047 [ERROR] trend_scanner.tools.twitter_scan_tool: Failed to search tweets: status: 429, message: "Rate limit exceeded
"
2025-11-28 02:34:59,047 [ERROR] trend_scanner.tools.twitter_scan_tool: Traceback (most recent call last):
  File "C:\PF\Projects\MumbaiHacks\trend_scanner\tools\twitter_scan_tool.py", line 585, in _run_async
    search_results = await client.search_tweet(target, 'Latest')
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 731, in search_tweet
    response, _ = await self.gql.search_timeline(query, product, count, cursor)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 159, in search_timeline
    return await self.gql_get(Endpoint.SEARCH_TIMELINE, variables, FEATURES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\gql.py", line 124, in gql_get
    return await self.base.get(url, params=flatten_params(params), headers=headers, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 211, in get
    return await self.request('GET', url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\PF\Projects\MumbaiHacks\.venv\Lib\site-packages\twikit\client\client.py", line 198, in request
    raise TooManyRequests(message, headers=response.headers)
twikit.errors.TooManyRequests: status: 429, message: "Rate limit exceeded
"

2025-11-28 02:34:59,048 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: Puma
2025-11-28 02:35:08,634 [INFO] trend_scanner.google_agents: Executing cross-platform risk assessment
2025-11-28 02:36:13,299 [INFO] trend_scanner.google_agents: Content Risk Assessor provided with 45 posts from multiple platforms for cross-platform analysis
2025-11-28 02:36:24,851 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,852 [INFO] trend_scanner.google_agents: Processed Twitter scan: 2 posts
2025-11-28 02:36:24,852 [INFO] trend_scanner.google_agents: Processed Twitter scan: 2 posts
2025-11-28 02:36:24,852 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,852 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,852 [INFO] trend_scanner.google_agents: Processed Twitter scan: 5 posts
2025-11-28 02:36:24,852 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,852 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,852 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,852 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,852 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,853 [INFO] trend_scanner.google_agents: Processed Twitter scan: 1 posts
2025-11-28 02:36:24,853 [INFO] trend_scanner.google_agents: Processed Twitter scan: 12 posts
2025-11-28 02:36:24,853 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,853 [INFO] trend_scanner.google_agents: Processed Twitter scan: 17 posts
2025-11-28 02:36:24,853 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,853 [INFO] trend_scanner.google_agents: Processed Twitter scan: 1 posts
2025-11-28 02:36:24,854 [INFO] trend_scanner.google_agents: Processed Twitter scan: 5 posts
2025-11-28 02:36:24,854 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,854 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,854 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,854 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,854 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,854 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,854 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,854 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,854 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,854 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,855 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,855 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,855 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,855 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,855 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,855 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,855 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,855 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,856 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,856 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 02:36:24,856 [INFO] trend_scanner.google_agents: Multi-platform scan completed - Reddit: 0, Threads: 0, Telegram: 0, Twitter: 45, Total: 45
2025-11-28 02:37:05,908 [INFO] __main__: Workflow completed: 1/1 tasks successful
2025-11-28 02:37:05,908 [INFO] __main__: Found 45 posts from trend scanner, preparing for verification...
2025-11-28 02:37:05,908 [INFO] __main__: Prepared 45 claims for verification
2025-11-28 02:37:05,908 [INFO] __main__: Step 2: Executing claim verification with batch processing...
2025-11-28 02:37:05,908 [INFO] __main__: Starting Google Agents workflow with 1 tasks
2025-11-28 02:37:05,908 [INFO] __main__: Executing task 1/1: verifier_coordinator - Verify extracted claims using comprehensive fact-checking workflow
2025-11-28 02:37:05,908 [INFO] __main__: Agent Claim Verification Coordinator has 1 tools available
2025-11-28 02:37:05,908 [INFO] __main__: Tool 0: <class 'claim_verifier.agents.ClaimVerifierOrchestrator'> with methods: ['claim_extractor', 'fact_checker', 'fact_verifier', 'gemini_api_key', 'google_agents', 'priority_assessor', 'quick_verify', 'report_generator', 'verify_content']...
2025-11-28 02:37:05,908 [INFO] __main__: Starting tool detection for task: 'Verify extracted claims using comprehensive fact-checking workflow'
2025-11-28 02:37:05,908 [INFO] __main__: Checking conditions:
2025-11-28 02:37:05,908 [INFO] __main__:   - hasattr(tool, '__call__'): False
2025-11-28 02:37:05,908 [INFO] __main__:   - 'scan' in task_description.lower(): False
2025-11-28 02:37:05,908 [INFO] __main__:   - hasattr(tool, 'verify_content'): True
2025-11-28 02:37:05,908 [INFO] __main__:   - 'verify' in task_description.lower(): True
2025-11-28 02:37:05,908 [INFO] __main__:   - hasattr(tool, 'execute_workflow'): False
2025-11-28 02:37:05,908 [INFO] __main__:   - hasattr(tool, 'batch_create_posts'): False
2025-11-28 02:37:05,908 [INFO] __main__:   - 'explanation' in task_description.lower(): False
2025-11-28 02:37:05,908 [INFO] __main__:   - hasattr(tool, 'create_debunk_post'): False
2025-11-28 02:37:05,908 [INFO] __main__: Agent Claim Verification Coordinator executing claim verification tool with batch processing...
2025-11-28 02:37:05,908 [INFO] __main__: Processing 45 claims using batch verification...
2025-11-28 02:37:05,908 [INFO] claim_verifier.agents: Starting Google Agents claim verification for 45 content items with batch processing
2025-11-28 02:37:05,908 [INFO] claim_verifier.agents: Processing 45 claims in batches of 15
2025-11-28 02:37:05,908 [INFO] claim_verifier.agents: Processing batch 1: claims 1-15
2025-11-28 02:38:11,386 [INFO] claim_verifier.agents: Processing batch 2: claims 16-30
2025-11-28 02:38:52,305 [INFO] claim_verifier.agents: Processing batch 3: claims 31-45
2025-11-28 02:39:42,262 [INFO] claim_verifier.agents: Batch verification completed: 45 total claims processed
2025-11-28 02:39:42,262 [INFO] __main__: Workflow completed: 1/1 tasks successful
2025-11-28 02:39:42,262 [INFO] __main__: Extracted 45 verified claims for explanation generation
2025-11-28 02:39:42,262 [INFO] __main__: Processing 45 verified claims for explanation generation
2025-11-28 02:39:42,262 [INFO] __main__: Claim 0: verdict='uncertain', verified=False, claim_text='Israeli occupation forces assaulted and blindfolde...'
2025-11-28 02:39:42,262 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,262 [INFO] __main__:   Found 1 source links and 1 source titles
2025-11-28 02:39:42,262 [INFO] __main__: ✅ INCLUDING claim for debunk post: Israeli occupation forces assaulted and blindfolde... (verdict: uncertain)
2025-11-28 02:39:42,262 [INFO] __main__:   Sources included: 1 links
2025-11-28 02:39:42,262 [INFO] __main__: Claim 1: verdict='mixed', verified=False, claim_text='A Palestinian NHS doctor in the UK was suspended f...'
2025-11-28 02:39:42,262 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,262 [INFO] __main__:   Found 5 source links and 5 source titles
2025-11-28 02:39:42,262 [INFO] __main__: ✅ INCLUDING claim for debunk post: A Palestinian NHS doctor in the UK was suspended f... (verdict: mixed)
2025-11-28 02:39:42,262 [INFO] __main__:   Sources included: 5 links
2025-11-28 02:39:42,262 [INFO] __main__: Claim 2: verdict='uncertain', verified=False, claim_text='This post consists solely of numerous Twitter ment...'
2025-11-28 02:39:42,262 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,262 [INFO] __main__:   Found 5 source links and 5 source titles
2025-11-28 02:39:42,262 [INFO] __main__: ✅ INCLUDING claim for debunk post: This post consists solely of numerous Twitter ment... (verdict: uncertain)
2025-11-28 02:39:42,262 [INFO] __main__:   Sources included: 5 links
2025-11-28 02:39:42,262 [INFO] __main__: Claim 3: verdict='false', verified=False, claim_text='The post suggests expelling 6 crore Muslims from I...'
2025-11-28 02:39:42,262 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,262 [INFO] __main__:   Found 5 source links and 5 source titles
2025-11-28 02:39:42,262 [INFO] __main__: ✅ INCLUDING claim for debunk post: The post suggests expelling 6 crore Muslims from I... (verdict: false)
2025-11-28 02:39:42,262 [INFO] __main__:   Sources included: 5 links
2025-11-28 02:39:42,262 [INFO] __main__: Claim 4: verdict='mixed', verified=False, claim_text='The post highlights the Guru's supreme importance,...'
2025-11-28 02:39:42,262 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,262 [INFO] __main__:   Found 5 source links and 5 source titles
2025-11-28 02:39:42,262 [INFO] __main__: ✅ INCLUDING claim for debunk post: The post highlights the Guru's supreme importance,... (verdict: mixed)
2025-11-28 02:39:42,262 [INFO] __main__:   Sources included: 5 links
2025-11-28 02:39:42,262 [INFO] __main__: Claim 5: verdict='uncertain', verified=False, claim_text='The user claims their relative, a BJP/RSS supporte...'
2025-11-28 02:39:42,262 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,262 [INFO] __main__:   Found 5 source links and 5 source titles
2025-11-28 02:39:42,262 [INFO] __main__: ✅ INCLUDING claim for debunk post: The user claims their relative, a BJP/RSS supporte... (verdict: uncertain)
2025-11-28 02:39:42,262 [INFO] __main__:   Sources included: 5 links
2025-11-28 02:39:42,262 [INFO] __main__: Claim 6: verdict='uncertain', verified=False, claim_text='The user claims harassment from a Shankarmutt pres...'
2025-11-28 02:39:42,262 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,262 [INFO] __main__:   Found 3 source links and 3 source titles
2025-11-28 02:39:42,262 [INFO] __main__: ✅ INCLUDING claim for debunk post: The user claims harassment from a Shankarmutt pres... (verdict: uncertain)
2025-11-28 02:39:42,262 [INFO] __main__:   Sources included: 3 links
2025-11-28 02:39:42,262 [INFO] __main__: Claim 7: verdict='uncertain', verified=False, claim_text='Spiritual practices in educational institutions ar...'
2025-11-28 02:39:42,262 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,262 [INFO] __main__:   Found 2 source links and 2 source titles
2025-11-28 02:39:42,262 [INFO] __main__: ✅ INCLUDING claim for debunk post: Spiritual practices in educational institutions ar... (verdict: uncertain)
2025-11-28 02:39:42,262 [INFO] __main__:   Sources included: 2 links
2025-11-28 02:39:42,262 [INFO] __main__: Claim 8: verdict='uncertain', verified=False, claim_text='The user expresses violent anger towards an indivi...'
2025-11-28 02:39:42,262 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,262 [INFO] __main__:   Found 1 source links and 1 source titles
2025-11-28 02:39:42,262 [INFO] __main__: ✅ INCLUDING claim for debunk post: The user expresses violent anger towards an indivi... (verdict: uncertain)
2025-11-28 02:39:42,262 [INFO] __main__:   Sources included: 1 links
2025-11-28 02:39:42,262 [INFO] __main__: Claim 9: verdict='true', verified=True, claim_text='Anushka Sharma was acquired by Gujarat Giants for ...'
2025-11-28 02:39:42,262 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,268 [INFO] __main__: ❌ EXCLUDING claim from debunk posts: verdict='true', verified=True
2025-11-28 02:39:42,268 [INFO] __main__: Claim 10: verdict='uncertain', verified=False, claim_text='The post is a call to achieve 70,000 posts related...'
2025-11-28 02:39:42,268 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,269 [INFO] __main__:   Found 5 source links and 5 source titles
2025-11-28 02:39:42,269 [INFO] __main__: ✅ INCLUDING claim for debunk post: The post is a call to achieve 70,000 posts related... (verdict: uncertain)
2025-11-28 02:39:42,269 [INFO] __main__:   Sources included: 5 links
2025-11-28 02:39:42,269 [INFO] __main__: Claim 11: verdict='uncertain', verified=False, claim_text='The post is a call to achieve 70,000 posts related...'
2025-11-28 02:39:42,269 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,269 [INFO] __main__:   Found 5 source links and 5 source titles
2025-11-28 02:39:42,269 [INFO] __main__: ✅ INCLUDING claim for debunk post: The post is a call to achieve 70,000 posts related... (verdict: uncertain)
2025-11-28 02:39:42,269 [INFO] __main__:   Sources included: 5 links
2025-11-28 02:39:42,269 [INFO] __main__: Claim 12: verdict='true', verified=True, claim_text='The post wishes good morning and seeks blessings f...'
2025-11-28 02:39:42,269 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,269 [INFO] __main__: ❌ EXCLUDING claim from debunk posts: verdict='true', verified=True
2025-11-28 02:39:42,269 [INFO] __main__: Claim 13: verdict='true', verified=True, claim_text='The post wishes good morning, asking Lord Ganesh t...'
2025-11-28 02:39:42,269 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,269 [INFO] __main__: ❌ EXCLUDING claim from debunk posts: verdict='true', verified=True
2025-11-28 02:39:42,269 [INFO] __main__: Claim 14: verdict='uncertain', verified=False, claim_text='The post is a call to achieve 70,000 posts related...'
2025-11-28 02:39:42,269 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,269 [INFO] __main__:   Found 5 source links and 5 source titles
2025-11-28 02:39:42,269 [INFO] __main__: ✅ INCLUDING claim for debunk post: The post is a call to achieve 70,000 posts related... (verdict: uncertain)
2025-11-28 02:39:42,269 [INFO] __main__:   Sources included: 5 links
2025-11-28 02:39:42,269 [INFO] __main__: Claim 15: verdict='error', verified=False, claim_text='The post is a call to achieve 70,000 posts related...'
2025-11-28 02:39:42,269 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,269 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,269 [INFO] __main__: ✅ INCLUDING claim for debunk post: The post is a call to achieve 70,000 posts related... (verdict: error)
2025-11-28 02:39:42,269 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,269 [INFO] __main__: Claim 16: verdict='error', verified=False, claim_text='Rajasthan should increase the number of permanent ...'
2025-11-28 02:39:42,269 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,269 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,269 [INFO] __main__: ✅ INCLUDING claim for debunk post: Rajasthan should increase the number of permanent ... (verdict: error)
2025-11-28 02:39:42,269 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,269 [INFO] __main__: Claim 17: verdict='error', verified=False, claim_text='The post is a call to achieve 70,000 posts related...'
2025-11-28 02:39:42,272 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,272 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,272 [INFO] __main__: ✅ INCLUDING claim for debunk post: The post is a call to achieve 70,000 posts related... (verdict: error)
2025-11-28 02:39:42,273 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,273 [INFO] __main__: Claim 18: verdict='error', verified=False, claim_text='The post is a call to achieve 70,000 posts related...'
2025-11-28 02:39:42,274 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,274 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,274 [INFO] __main__: ✅ INCLUDING claim for debunk post: The post is a call to achieve 70,000 posts related... (verdict: error)
2025-11-28 02:39:42,274 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,274 [INFO] __main__: Claim 19: verdict='error', verified=False, claim_text='The post is a call to achieve 70,000 posts related...'
2025-11-28 02:39:42,274 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,274 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,274 [INFO] __main__: ✅ INCLUDING claim for debunk post: The post is a call to achieve 70,000 posts related... (verdict: error)
2025-11-28 02:39:42,274 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,274 [INFO] __main__: Claim 20: verdict='error', verified=False, claim_text='The post is a call to achieve 70,000 posts related...'
2025-11-28 02:39:42,274 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,274 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,274 [INFO] __main__: ✅ INCLUDING claim for debunk post: The post is a call to achieve 70,000 posts related... (verdict: error)
2025-11-28 02:39:42,274 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,274 [INFO] __main__: Claim 21: verdict='error', verified=False, claim_text='The post is a call to achieve 70,000 posts related...'
2025-11-28 02:39:42,274 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,274 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,274 [INFO] __main__: ✅ INCLUDING claim for debunk post: The post is a call to achieve 70,000 posts related... (verdict: error)
2025-11-28 02:39:42,274 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,274 [INFO] __main__: Claim 22: verdict='error', verified=False, claim_text='The trailer for Elvish Yadav's project "AUKAAT KE ...'
2025-11-28 02:39:42,274 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,274 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,274 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for Elvish Yadav's project "AUKAAT KE ... (verdict: error)
2025-11-28 02:39:42,274 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,274 [INFO] __main__: Claim 23: verdict='error', verified=False, claim_text='The trailer for Elvish Yadav's "AUKAAT KE BAHAR" h...'
2025-11-28 02:39:42,274 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,274 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,274 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for Elvish Yadav's "AUKAAT KE BAHAR" h... (verdict: error)
2025-11-28 02:39:42,274 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,274 [INFO] __main__: Claim 24: verdict='error', verified=False, claim_text='The trailer for Elvish Yadav's "AUKAAT KE BAHAR" h...'
2025-11-28 02:39:42,274 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,274 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,274 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for Elvish Yadav's "AUKAAT KE BAHAR" h... (verdict: error)
2025-11-28 02:39:42,274 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,274 [INFO] __main__: Claim 25: verdict='error', verified=False, claim_text='The trailer for "AUKAAT KE BAHAR" has been release...'
2025-11-28 02:39:42,274 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,274 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,274 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for "AUKAAT KE BAHAR" has been release... (verdict: error)
2025-11-28 02:39:42,274 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,274 [INFO] __main__: Claim 26: verdict='error', verified=False, claim_text='The trailer for "AUKAAT KE BAHAR" has been release...'
2025-11-28 02:39:42,279 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,279 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,279 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for "AUKAAT KE BAHAR" has been release... (verdict: error)
2025-11-28 02:39:42,279 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,280 [INFO] __main__: Claim 27: verdict='error', verified=False, claim_text='The trailer for "AUKAAT KE BAHAR" has been release...'
2025-11-28 02:39:42,280 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,280 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,281 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for "AUKAAT KE BAHAR" has been release... (verdict: error)
2025-11-28 02:39:42,281 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,281 [INFO] __main__: Claim 28: verdict='error', verified=False, claim_text='The trailer for Elvish Yadav's "AUKAAT KE BAHAR" h...'
2025-11-28 02:39:42,281 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,281 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,281 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for Elvish Yadav's "AUKAAT KE BAHAR" h... (verdict: error)
2025-11-28 02:39:42,281 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,281 [INFO] __main__: Claim 29: verdict='error', verified=False, claim_text='The trailer for Elvish Yadav's "AUKAAT KE BAHAR" h...'
2025-11-28 02:39:42,281 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,281 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,281 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for Elvish Yadav's "AUKAAT KE BAHAR" h... (verdict: error)
2025-11-28 02:39:42,281 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,281 [INFO] __main__: Claim 30: verdict='error', verified=False, claim_text='The trailer for "AUKAAT KE BAHAR" has been release...'
2025-11-28 02:39:42,281 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,281 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,281 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for "AUKAAT KE BAHAR" has been release... (verdict: error)
2025-11-28 02:39:42,281 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,281 [INFO] __main__: Claim 31: verdict='error', verified=False, claim_text='The trailer for Elvish Yadav's "AUKAAT KE BAHAR" h...'
2025-11-28 02:39:42,281 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,281 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,281 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for Elvish Yadav's "AUKAAT KE BAHAR" h... (verdict: error)
2025-11-28 02:39:42,281 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,281 [INFO] __main__: Claim 32: verdict='error', verified=False, claim_text='The trailer for Elvish Yadav's debut series "Aukaa...'
2025-11-28 02:39:42,281 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,281 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,281 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for Elvish Yadav's debut series "Aukaa... (verdict: error)
2025-11-28 02:39:42,281 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,281 [INFO] __main__: Claim 33: verdict='error', verified=False, claim_text='The trailer for "AUKAAT KE BAHAR" has been release...'
2025-11-28 02:39:42,281 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,281 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,281 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for "AUKAAT KE BAHAR" has been release... (verdict: error)
2025-11-28 02:39:42,281 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,281 [INFO] __main__: Claim 34: verdict='error', verified=False, claim_text='The trailer for "AUKAAT KE BAHAR" has been release...'
2025-11-28 02:39:42,281 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,281 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,281 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for "AUKAAT KE BAHAR" has been release... (verdict: error)
2025-11-28 02:39:42,281 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,281 [INFO] __main__: Claim 35: verdict='error', verified=False, claim_text='The trailer for "AUKAAT KE BAHAR" has been release...'
2025-11-28 02:39:42,281 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,281 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,281 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for "AUKAAT KE BAHAR" has been release... (verdict: error)
2025-11-28 02:39:42,281 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,281 [INFO] __main__: Claim 36: verdict='error', verified=False, claim_text='The trailer for "AUKAAT KE BAHAR" is out, and it's...'
2025-11-28 02:39:42,281 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,281 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,281 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for "AUKAAT KE BAHAR" is out, and it's... (verdict: error)
2025-11-28 02:39:42,281 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,281 [INFO] __main__: Claim 37: verdict='error', verified=False, claim_text='The trailer for "AUKAAT KE BAHAR" has been release...'
2025-11-28 02:39:42,281 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,286 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,286 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for "AUKAAT KE BAHAR" has been release... (verdict: error)
2025-11-28 02:39:42,286 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,286 [INFO] __main__: Claim 38: verdict='error', verified=False, claim_text='The trailer for "Aukaat Ke Bahar" is finally out, ...'
2025-11-28 02:39:42,286 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,286 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,286 [INFO] __main__: ✅ INCLUDING claim for debunk post: The trailer for "Aukaat Ke Bahar" is finally out, ... (verdict: error)
2025-11-28 02:39:42,286 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,286 [INFO] __main__: Claim 39: verdict='error', verified=False, claim_text='Scientists are now acknowledging that mantra waves...'
2025-11-28 02:39:42,287 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,287 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,287 [INFO] __main__: ✅ INCLUDING claim for debunk post: Scientists are now acknowledging that mantra waves... (verdict: error)
2025-11-28 02:39:42,287 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,287 [INFO] __main__: Claim 40: verdict='error', verified=False, claim_text='The post presents the strongest playing XI for UP ...'
2025-11-28 02:39:42,287 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,287 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,287 [INFO] __main__: ✅ INCLUDING claim for debunk post: The post presents the strongest playing XI for UP ... (verdict: error)
2025-11-28 02:39:42,287 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,287 [INFO] __main__: Claim 41: verdict='error', verified=False, claim_text='UP Warriorz made significant player selections in ...'
2025-11-28 02:39:42,287 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,287 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,287 [INFO] __main__: ✅ INCLUDING claim for debunk post: UP Warriorz made significant player selections in ... (verdict: error)
2025-11-28 02:39:42,287 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,287 [INFO] __main__: Claim 42: verdict='error', verified=False, claim_text='Alyssa Healy and Alana King went unsold in the WPL...'
2025-11-28 02:39:42,287 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,287 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,287 [INFO] __main__: ✅ INCLUDING claim for debunk post: Alyssa Healy and Alana King went unsold in the WPL... (verdict: error)
2025-11-28 02:39:42,287 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,287 [INFO] __main__: Claim 43: verdict='error', verified=False, claim_text='Indian pacer Shikha Pandey was acquired by UP Warr...'
2025-11-28 02:39:42,287 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,287 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,287 [INFO] __main__: ✅ INCLUDING claim for debunk post: Indian pacer Shikha Pandey was acquired by UP Warr... (verdict: error)
2025-11-28 02:39:42,287 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,287 [INFO] __main__: Claim 44: verdict='error', verified=False, claim_text='The post presents the complete squad of UP Warrior...'
2025-11-28 02:39:42,287 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 02:39:42,287 [INFO] __main__:   Found 0 source links and 0 source titles
2025-11-28 02:39:42,287 [INFO] __main__: ✅ INCLUDING claim for debunk post: The post presents the complete squad of UP Warrior... (verdict: error)
2025-11-28 02:39:42,287 [INFO] __main__:   Sources included: 0 links
2025-11-28 02:39:42,287 [INFO] __main__: Verdict distribution: {'uncertain': 9, 'mixed': 2, 'false': 1, 'true': 3, 'error': 30}
2025-11-28 02:39:42,287 [INFO] __main__: Total claims for debunk posts: 42 out of 45
2025-11-28 02:39:42,287 [INFO] __main__: Step 3: Executing explanation generation with batch processing for 42 misinformation claims...
2025-11-28 02:39:42,287 [INFO] __main__: Starting Google Agents workflow with 1 tasks
2025-11-28 02:39:42,287 [INFO] __main__: Executing task 1/1: explanation_coordinator - Generate debunk posts for misinformation claims using batch processing
2025-11-28 02:39:42,287 [INFO] __main__: Agent Explanation Generation Coordinator has 1 tools available
2025-11-28 02:39:42,287 [INFO] __main__: Tool 0: <class 'explanation_agent.agents.ExplanationAgent'> with methods: ['batch_create_posts', 'content_generator', 'create_debunk_post', 'orchestrator', 'source_analyzer']...
2025-11-28 02:39:42,287 [INFO] __main__: Starting tool detection for task: 'Generate debunk posts for misinformation claims using batch processing'
2025-11-28 02:39:42,287 [INFO] __main__: Checking conditions:
2025-11-28 02:39:42,287 [INFO] __main__:   - hasattr(tool, '__call__'): False
2025-11-28 02:39:42,287 [INFO] __main__:   - 'scan' in task_description.lower(): False
2025-11-28 02:39:42,287 [INFO] __main__:   - hasattr(tool, 'verify_content'): False
2025-11-28 02:39:42,287 [INFO] __main__:   - 'verify' in task_description.lower(): False
2025-11-28 02:39:42,287 [INFO] __main__:   - hasattr(tool, 'execute_workflow'): False
2025-11-28 02:39:42,287 [INFO] __main__:   - hasattr(tool, 'batch_create_posts'): True
2025-11-28 02:39:42,287 [INFO] __main__:   - 'explanation' in task_description.lower(): False
2025-11-28 02:39:42,287 [INFO] __main__:   - hasattr(tool, 'create_debunk_post'): True
2025-11-28 02:39:42,287 [INFO] __main__: Agent Explanation Generation Coordinator executing ExplanationAgent with batch processing...
2025-11-28 02:39:42,287 [INFO] __main__: Tool type: <class 'explanation_agent.agents.ExplanationAgent'>
2025-11-28 02:39:42,287 [INFO] __main__: Tool methods: ['batch_create_posts', 'content_generator', 'create_debunk_post', 'orchestrator', 'source_analyzer']
2025-11-28 02:39:42,287 [INFO] __main__: Task description: 'Generate debunk posts for misinformation claims using batch processing'
2025-11-28 02:39:42,287 [INFO] __main__: Task description contains 'explanation': False
2025-11-28 02:39:42,287 [INFO] __main__: Tool has batch_create_posts: True
2025-11-28 02:39:42,287 [INFO] __main__: Received verification_results: 42 items
2025-11-28 02:39:42,287 [INFO] __main__: Found 42 verification results for explanation generation
2025-11-28 02:39:42,287 [INFO] __main__: Verification result 0: keys = ['claim_text', 'verification', 'sources', 'source', 'content_summary', 'verified', 'verdict']
2025-11-28 02:39:42,293 [INFO] __main__: Verification result 1: keys = ['claim_text', 'verification', 'sources', 'source', 'content_summary', 'verified', 'verdict']
2025-11-28 02:39:42,293 [INFO] __main__: Creating debunk posts for 42 claims using batch processing...
2025-11-28 02:39:42,293 [INFO] explanation_agent.agents: Creating 42 debunk posts with batch Google Agents processing...
2025-11-28 02:39:42,293 [INFO] explanation_agent.agents: Processing batch 1: posts 1-10
2025-11-28 02:39:42,293 [INFO] explanation_agent.agents: Agent Content Generation Specialist executing batch processing tool...
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Raw Gemini response (first 500 chars): ```json
[
    {
        "heading": "Unverified Claim: Palestinian Assault in Beit Ummar Lacks Specific Evidence",
        "body": "The claim circulating about Israeli occupation forces assaulting and blindfolding a Palestinian at gunpoint in Beit Ummar remains unverified. While reports of military operations in the West Bank and concerns about human rights exist, including general accounts of Israeli army night raids, no specific, independently corroborated evidence has emerged to confirm the de
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Cleaned response (first 500 chars): [
    {
        "heading": "Unverified Claim: Palestinian Assault in Beit Ummar Lacks Specific Evidence",
        "body": "The claim circulating about Israeli occupation forces assaulting and blindfolding a Palestinian at gunpoint in Beit Ummar remains unverified. While reports of military operations in the West Bank and concerns about human rights exist, including general accounts of Israeli army night raids, no specific, independently corroborated evidence has emerged to confirm the details of
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Extracted JSON: [
    {
        "heading": "Unverified Claim: Palestinian Assault in Beit Ummar Lacks Specific Evidence",
        "body": "The claim circulating about Israeli occupation forces assaulting and blindfolding a Palestinian at gunpoint in Beit Ummar remains unverified. While reports of military operations in the West Bank and concerns about human rights exist, including general accounts of Israeli army night raids, no specific, independently corroborated evidence has emerged to confirm the details of
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Agent Source Analysis Specialist executing batch processing tool...
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Processing batch sources for 10 verification results
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Verification result 0: 1 links, 1 titles
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents:   Links: ['https://www.aljazeera.com/gallery/2015/8/15/israeli-army-night-raids-spread-fear-in-west-bank']
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents:   Titles: ['Israeli army night raids spread fear in West Bank | Human Rights | Al ...']
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Verification result 0: Created 1 source entries
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Verification result 1: 5 links, 5 titles
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents:   Links: ['https://www.theguardian.com/world/palestinian-territories', 'https://www.theguardian.com/uk/london']
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents:   Titles: ['Palestine | The Guardian', 'London | The Guardian']
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Verification result 1: Created 5 source entries
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Verification result 2: 5 links, 5 titles
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents:   Links: ['https://www.pbs.org/newshour/politics/heres-where-donald-trump-stands-on-key-policies-ahead-of-his-second-administration', 'https://www.nytimes.com/interactive/2019/08/14/magazine/black-history-american-democracy.html']
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents:   Titles: ["Here's where Donald Trump stands on key policies ahead of his ...", "America Wasn't a Democracy, Until Black Americans Made It One ..."]
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Verification result 2: Created 5 source entries
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Verification result 3: 5 links, 5 titles
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents:   Links: ['https://indianexpress.com/article/india/mha-sets-30-day-limit-to-verify-credentials-of-illegal-immigrants-from-bangla-myanmar-10014683/', 'https://www.thehindu.com/opinion/op-ed/a-nuanced-and-compassionate-understanding-of-rohingyas-flight-is-the-need-of-the-hour/article68987784.ece']
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents:   Titles: ["MHA sets 30-day limit to verify credentials of 'illegal' immigrants from ...", "A nuanced and compassionate understanding of Rohingya's flight is ..."]
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Verification result 3: Created 5 source entries
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Verification result 4: 5 links, 5 titles
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents:   Links: ['https://www.thehindu.com/society/faith/importance-of-a-guru/article69890212.ece', 'https://www.thehindu.com/society/faith/importance-of-guru-bhakti/article67048711.ece']
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents:   Titles: ['Importance of a guru - The Hindu', 'Importance of guru bhakti - The Hindu']
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Verification result 4: Created 5 source entries
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents: Verification result 5: 5 links, 5 titles
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents:   Links: ['https://indianexpress.com/news-sitemap.xml', 'https://indianexpress.com/article/india/congress-bharat-jodo-yatra-live-updates-rahul-gandhi-kanyakumari-8135479/']
2025-11-28 02:40:11,243 [INFO] explanation_agent.agents:   Titles: ['https://indianexpress.com/news-sitemap.xml', "'Bharat Jodo Yatra is to connect with people, undo damage caused ..."]
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents: Verification result 5: Created 5 source entries
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents: Verification result 6: 3 links, 3 titles
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents:   Links: ['https://www.thehindu.com/news/national/karnataka/gauri-lankeshs-remarks-unwarranted-association/article6904273.ece', 'https://www.thehindu.com/news/national/sc-stops-coronation-of-swami-avimukteshwaranand-saraswati-as-shankaracharya-of-jyotish-peeth/article66014458.ece']
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents:   Titles: ["Gauri Lankesh's remarks unwarranted: association - The Hindu", 'SC stops coronation of Swami Avimukteshwaranand Saraswati as ...']
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents: Verification result 6: Created 3 source entries
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents: Verification result 7: 2 links, 2 titles
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents:   Links: ['https://www.theatlantic.com/magazine/archive/2025/02/american-loneliness-personality-politics/681091/', 'https://www.nytimes.com/interactive/2020/world/coronavirus-tips-advice.html']
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents:   Titles: ['The Anti-Social Century - The Atlantic', 'Answers to Your Current Coronavirus Questions - The New York ...']
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents: Verification result 7: Created 2 source entries
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents: Verification result 8: 1 links, 1 titles
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents:   Links: ['https://www.npr.org/2010/08/21/129175964/on-the-scale-of-evil-where-do-murderers-rate']
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents:   Titles: ['On The Scale Of Evil, Where Do Murderers Rate? : NPR']
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents: Verification result 8: Created 1 source entries
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents: Verification result 9: 5 links, 5 titles
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents:   Links: ['https://www.nytimes.com/2020/07/18/world/coronavirus-news.html', 'https://www.nytimes.com/live/2022/05/28/us/texas-school-shooting']
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents:   Titles: ['Trump Administration Aims to Block New Funding for Coronavirus ...', 'Uvalde Elementary School Shooting: As Uvalde Meets to Mourn, a ...']
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents: Verification result 9: Created 5 source entries
2025-11-28 02:40:11,250 [INFO] explanation_agent.agents: Batch source analysis completed: 47 total sources processed
2025-11-28 02:40:11,260 [INFO] explanation_agent.agents: Processing batch 2: posts 11-20
2025-11-28 02:40:11,260 [INFO] explanation_agent.agents: Agent Content Generation Specialist executing batch processing tool...
2025-11-28 02:40:27,823 [INFO] explanation_agent.agents: Raw Gemini response (first 500 chars): ```json
[
    {
        "heading": "No Evidence Confirms 'Fourth Grade' Hashtag Call for 70,000 Posts",
        "body": "A social media claim circulating suggests there's a specific call to generate 70,000 posts related to 'Fourth Grade' using a particular hashtag. However, our investigation found no verifiable evidence to support this claim. The provided sources, which reference unrelated New York Times articles about Trump administration funding and the Uvalde school shooting, offer no informa
2025-11-28 02:40:27,823 [INFO] explanation_agent.agents: Cleaned response (first 500 chars): [
    {
        "heading": "No Evidence Confirms 'Fourth Grade' Hashtag Call for 70,000 Posts",
        "body": "A social media claim circulating suggests there's a specific call to generate 70,000 posts related to 'Fourth Grade' using a particular hashtag. However, our investigation found no verifiable evidence to support this claim. The provided sources, which reference unrelated New York Times articles about Trump administration funding and the Uvalde school shooting, offer no information per
2025-11-28 02:40:27,823 [INFO] explanation_agent.agents: Extracted JSON: [
    {
        "heading": "No Evidence Confirms 'Fourth Grade' Hashtag Call for 70,000 Posts",
        "body": "A social media claim circulating suggests there's a specific call to generate 70,000 posts related to 'Fourth Grade' using a particular hashtag. However, our investigation found no verifiable evidence to support this claim. The provided sources, which reference unrelated New York Times articles about Trump administration funding and the Uvalde school shooting, offer no information per
2025-11-28 02:40:27,823 [INFO] explanation_agent.agents: Agent Source Analysis Specialist executing batch processing tool...
2025-11-28 02:40:27,823 [INFO] explanation_agent.agents: Processing batch sources for 10 verification results
2025-11-28 02:40:27,823 [INFO] explanation_agent.agents: Verification result 0: 5 links, 5 titles
2025-11-28 02:40:27,823 [INFO] explanation_agent.agents:   Links: ['https://www.nytimes.com/2020/07/18/world/coronavirus-news.html', 'https://www.nytimes.com/live/2022/05/28/us/texas-school-shooting']
2025-11-28 02:40:27,823 [INFO] explanation_agent.agents:   Titles: ['Trump Administration Aims to Block New Funding for Coronavirus ...', 'Uvalde Elementary School Shooting: As Uvalde Meets to Mourn, a ...']
2025-11-28 02:40:27,823 [INFO] explanation_agent.agents: Verification result 0: Created 5 source entries
2025-11-28 02:40:27,823 [INFO] explanation_agent.agents: Verification result 1: 5 links, 5 titles
2025-11-28 02:40:27,823 [INFO] explanation_agent.agents:   Links: ['https://www.nytimes.com/2020/07/18/world/coronavirus-news.html', 'https://www.nytimes.com/live/2022/05/28/us/texas-school-shooting']
2025-11-28 02:40:27,823 [INFO] explanation_agent.agents:   Titles: ['Trump Administration Aims to Block New Funding for Coronavirus ...', 'Uvalde Elementary School Shooting: As Uvalde Meets to Mourn, a ...']
2025-11-28 02:40:27,823 [INFO] explanation_agent.agents: Verification result 1: Created 5 source entries
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 2: 0 links, 0 titles
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 2: Created 0 source entries
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 3: 0 links, 0 titles
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 3: Created 0 source entries
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 4: 0 links, 0 titles
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 4: Created 0 source entries
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 5: 0 links, 0 titles
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 5: Created 0 source entries
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 6: 0 links, 0 titles
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 6: Created 0 source entries
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 7: 0 links, 0 titles
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 7: Created 0 source entries
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 8: 0 links, 0 titles
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 8: Created 0 source entries
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 9: 0 links, 0 titles
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Verification result 9: Created 0 source entries
2025-11-28 02:40:27,830 [INFO] explanation_agent.agents: Batch source analysis completed: 20 total sources processed
2025-11-28 02:40:27,840 [INFO] explanation_agent.agents: Processing batch 3: posts 21-30
2025-11-28 02:40:27,840 [INFO] explanation_agent.agents: Agent Content Generation Specialist executing batch processing tool...
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Raw Gemini response (first 500 chars): ```json
[
    {
        "heading": "No Trailer Yet for Elvish Yadav's "AUKAAT KE BAHAR" Series",
        "body": "Contrary to circulating online claims, the trailer for Elvish Yadav's anticipated series, "AUKAAT KE BAHAR," has not been officially released. Reports suggesting its availability and an imminent December 3rd launch are currently unsubstantiated. A thorough review of Elvish Yadav's official social media channels and reputable entertainment news sources reveals no such trailer or offic
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Cleaned response (first 500 chars): [
    {
        "heading": "No Trailer Yet for Elvish Yadav's "AUKAAT KE BAHAR" Series",
        "body": "Contrary to circulating online claims, the trailer for Elvish Yadav's anticipated series, "AUKAAT KE BAHAR," has not been officially released. Reports suggesting its availability and an imminent December 3rd launch are currently unsubstantiated. A thorough review of Elvish Yadav's official social media channels and reputable entertainment news sources reveals no such trailer or official anno
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Extracted JSON: [
    {
        "heading": "No Trailer Yet for Elvish Yadav's "AUKAAT KE BAHAR" Series",
        "body": "Contrary to circulating online claims, the trailer for Elvish Yadav's anticipated series, "AUKAAT KE BAHAR," has not been officially released. Reports suggesting its availability and an imminent December 3rd launch are currently unsubstantiated. A thorough review of Elvish Yadav's official social media channels and reputable entertainment news sources reveals no such trailer or official anno
2025-11-28 02:40:51,900 [ERROR] explanation_agent.agents: JSON parsing error in batch content generation: Expecting ',' delimiter: line 3 column 56 (char 63)
2025-11-28 02:40:51,900 [ERROR] explanation_agent.agents: Response that failed to parse: [
    {
        "heading": "No Trailer Yet for Elvish Yadav's "AUKAAT KE BAHAR" Series",
        "body": "Contrary to circulating online claims, the trailer for Elvish Yadav's anticipated series, "AUKAAT KE BAHAR," has not been officially released. Reports suggesting its availability and an imminent December 3rd launch are currently unsubstantiated. A thorough review of Elvish Yadav's official social media channels and reputable entertainment news sources reveals no such trailer or official announcement regarding its release or the series' premiere date. While anticipation for his projects is understandable, this specific claim lacks factual basis. Fans should rely on official sources for accurate updates on the series' development and release schedule.",
        "summary": "The trailer for Elvish Yadav's "AUKAAT KE BAHAR" has not been released, and the December 3rd launch claim is unconfirmed."
    },
    {
        "heading": ""AUKAAT KE BAHAR" Trailer Claims Untrue: No Official Relea
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Agent Source Analysis Specialist executing batch processing tool...
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Processing batch sources for 10 verification results
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 0: 0 links, 0 titles
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 0: Created 0 source entries
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 1: 0 links, 0 titles
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 1: Created 0 source entries
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 2: 0 links, 0 titles
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 2: Created 0 source entries
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 3: 0 links, 0 titles
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 3: Created 0 source entries
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 4: 0 links, 0 titles
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 4: Created 0 source entries
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 5: 0 links, 0 titles
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 5: Created 0 source entries
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 6: 0 links, 0 titles
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 6: Created 0 source entries
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 7: 0 links, 0 titles
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 7: Created 0 source entries
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 8: 0 links, 0 titles
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 8: Created 0 source entries
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 9: 0 links, 0 titles
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Verification result 9: Created 0 source entries
2025-11-28 02:40:51,900 [INFO] explanation_agent.agents: Batch source analysis completed: 10 total sources processed
2025-11-28 02:40:51,900 [ERROR] explanation_agent.agents: Batch content generation failed: JSON parsing error: Expecting ',' delimiter: line 3 column 56 (char 63)
2025-11-28 02:40:51,915 [INFO] explanation_agent.agents: Processing batch 4: posts 31-40
2025-11-28 02:40:51,915 [INFO] explanation_agent.agents: Agent Content Generation Specialist executing batch processing tool...
2025-11-28 02:41:26,242 [INFO] explanation_agent.agents: Raw Gemini response (first 500 chars): ```json
[
    {
        "heading": "AUKAAT KE BAHAR Trailer: Old News, Not a Recent Release",
        "body": "The trailer for Elvish Yadav's web series \"Aukaat Ke Bahar\" was released back in November 2023, with the series itself debuting in December 2023 on Play Prime. This claim, if presented as current news, is inaccurate. The initial excitement and discussions around the trailer and the series are from several months ago, making any suggestion of a *recent* release or current major event m
2025-11-28 02:41:26,243 [INFO] explanation_agent.agents: Cleaned response (first 500 chars): [
    {
        "heading": "AUKAAT KE BAHAR Trailer: Old News, Not a Recent Release",
        "body": "The trailer for Elvish Yadav's web series \"Aukaat Ke Bahar\" was released back in November 2023, with the series itself debuting in December 2023 on Play Prime. This claim, if presented as current news, is inaccurate. The initial excitement and discussions around the trailer and the series are from several months ago, making any suggestion of a *recent* release or current major event misleadin
2025-11-28 02:41:26,243 [INFO] explanation_agent.agents: Extracted JSON: [
    {
        "heading": "AUKAAT KE BAHAR Trailer: Old News, Not a Recent Release",
        "body": "The trailer for Elvish Yadav's web series \"Aukaat Ke Bahar\" was released back in November 2023, with the series itself debuting in December 2023 on Play Prime. This claim, if presented as current news, is inaccurate. The initial excitement and discussions around the trailer and the series are from several months ago, making any suggestion of a *recent* release or current major event misleadin
2025-11-28 02:41:26,243 [INFO] explanation_agent.agents: Agent Source Analysis Specialist executing batch processing tool...
2025-11-28 02:41:26,243 [INFO] explanation_agent.agents: Processing batch sources for 10 verification results
2025-11-28 02:41:26,243 [INFO] explanation_agent.agents: Verification result 0: 0 links, 0 titles
2025-11-28 02:41:26,243 [INFO] explanation_agent.agents: Verification result 0: Created 0 source entries
2025-11-28 02:41:26,243 [INFO] explanation_agent.agents: Verification result 1: 0 links, 0 titles
2025-11-28 02:41:26,244 [INFO] explanation_agent.agents: Verification result 1: Created 0 source entries
2025-11-28 02:41:26,244 [INFO] explanation_agent.agents: Verification result 2: 0 links, 0 titles
2025-11-28 02:41:26,244 [INFO] explanation_agent.agents: Verification result 2: Created 0 source entries
2025-11-28 02:41:26,244 [INFO] explanation_agent.agents: Verification result 3: 0 links, 0 titles
2025-11-28 02:41:26,244 [INFO] explanation_agent.agents: Verification result 3: Created 0 source entries
2025-11-28 02:41:26,244 [INFO] explanation_agent.agents: Verification result 4: 0 links, 0 titles
2025-11-28 02:41:26,244 [INFO] explanation_agent.agents: Verification result 4: Created 0 source entries
2025-11-28 02:41:26,244 [INFO] explanation_agent.agents: Verification result 5: 0 links, 0 titles
2025-11-28 02:41:26,244 [INFO] explanation_agent.agents: Verification result 5: Created 0 source entries
2025-11-28 02:41:26,244 [INFO] explanation_agent.agents: Verification result 6: 0 links, 0 titles
2025-11-28 02:41:26,244 [INFO] explanation_agent.agents: Verification result 6: Created 0 source entries
2025-11-28 02:41:26,245 [INFO] explanation_agent.agents: Verification result 7: 0 links, 0 titles
2025-11-28 02:41:26,245 [INFO] explanation_agent.agents: Verification result 7: Created 0 source entries
2025-11-28 02:41:26,245 [INFO] explanation_agent.agents: Verification result 8: 0 links, 0 titles
2025-11-28 02:41:26,245 [INFO] explanation_agent.agents: Verification result 8: Created 0 source entries
2025-11-28 02:41:26,245 [INFO] explanation_agent.agents: Verification result 9: 0 links, 0 titles
2025-11-28 02:41:26,245 [INFO] explanation_agent.agents: Verification result 9: Created 0 source entries
2025-11-28 02:41:26,245 [INFO] explanation_agent.agents: Batch source analysis completed: 10 total sources processed
2025-11-28 02:41:26,252 [INFO] explanation_agent.agents: Processing batch 5: posts 41-42
2025-11-28 02:41:26,253 [INFO] explanation_agent.agents: Agent Content Generation Specialist executing batch processing tool...
2025-11-28 02:41:35,833 [INFO] explanation_agent.agents: Raw Gemini response (first 500 chars): ```json
[
    {
        "heading": "Debunked: Shikha Pandey's WPL Team, Price, and Auction Details Are Incorrect",
        "body": "The claim that Indian pacer Shikha Pandey was acquired by UP Warriorz for Rs 2.40 crore in a WPL 2026 Mega Auction is false. \n\n**Here's why:**\n\n1.  **Incorrect Team and Price:** Shikha Pandey was indeed a sought-after player in the Women's Premier League (WPL) auction. However, she was purchased by **Delhi Capitals**, not UP Warriorz, for **Rs 60 lakh** during t
2025-11-28 02:41:35,833 [INFO] explanation_agent.agents: Cleaned response (first 500 chars): [
    {
        "heading": "Debunked: Shikha Pandey's WPL Team, Price, and Auction Details Are Incorrect",
        "body": "The claim that Indian pacer Shikha Pandey was acquired by UP Warriorz for Rs 2.40 crore in a WPL 2026 Mega Auction is false. \n\n**Here's why:**\n\n1.  **Incorrect Team and Price:** Shikha Pandey was indeed a sought-after player in the Women's Premier League (WPL) auction. However, she was purchased by **Delhi Capitals**, not UP Warriorz, for **Rs 60 lakh** during the inaug
2025-11-28 02:41:35,833 [INFO] explanation_agent.agents: Extracted JSON: [
    {
        "heading": "Debunked: Shikha Pandey's WPL Team, Price, and Auction Details Are Incorrect",
        "body": "The claim that Indian pacer Shikha Pandey was acquired by UP Warriorz for Rs 2.40 crore in a WPL 2026 Mega Auction is false. \n\n**Here's why:**\n\n1.  **Incorrect Team and Price:** Shikha Pandey was indeed a sought-after player in the Women's Premier League (WPL) auction. However, she was purchased by **Delhi Capitals**, not UP Warriorz, for **Rs 60 lakh** during the inaug
2025-11-28 02:41:35,833 [INFO] explanation_agent.agents: Agent Source Analysis Specialist executing batch processing tool...
2025-11-28 02:41:35,833 [INFO] explanation_agent.agents: Processing batch sources for 2 verification results
2025-11-28 02:41:35,833 [INFO] explanation_agent.agents: Verification result 0: 0 links, 0 titles
2025-11-28 02:41:35,833 [INFO] explanation_agent.agents: Verification result 0: Created 0 source entries
2025-11-28 02:41:35,833 [INFO] explanation_agent.agents: Verification result 1: 0 links, 0 titles
2025-11-28 02:41:35,833 [INFO] explanation_agent.agents: Verification result 1: Created 0 source entries
2025-11-28 02:41:35,833 [INFO] explanation_agent.agents: Batch source analysis completed: 2 total sources processed
2025-11-28 02:41:35,833 [INFO] explanation_agent.agents: Batch processing completed: 42 total posts created
2025-11-28 02:41:35,833 [INFO] __main__: Tool result type: <class 'dict'>
2025-11-28 02:41:35,833 [INFO] __main__: Tool result keys: ['success', 'message', 'debunk_posts', 'batch_statistics']
2025-11-28 02:41:35,833 [INFO] __main__: Batch explanation generation completed successfully with 42 posts generated
2025-11-28 02:41:35,833 [INFO] __main__: ExplanationAgent tool execution completed - tool_used: True
2025-11-28 02:41:35,833 [INFO] __main__: Workflow completed: 1/1 tasks successful
2025-11-28 02:41:35,833 [INFO] __main__: Explanation generation completed: True
2025-11-28 02:41:35,833 [INFO] __main__: Step 4: Processing and combining all results...
2025-11-28 02:41:35,833 [INFO] __main__: Trend scanning completed: 45 posts
2025-11-28 02:41:35,833 [INFO] __main__: Claim verification completed: True
2025-11-28 02:41:35,833 [INFO] __main__: Batch verification processed 45 claims in batches of 15
2025-11-28 02:41:35,838 [INFO] __main__: Explanation generation completed: True
2025-11-28 02:41:35,838 [INFO] __main__: Batch explanation generation processed 42 claims in batches of 10
2025-11-28 02:41:35,838 [INFO] __main__: Successfully created 42 debunk posts
2025-11-28 02:41:35,838 [INFO] __main__: Extracted 42 debunk posts from explanation generation
2025-11-28 02:41:35,856 [INFO] __main__: Google Agents results saved to: orchestrator_results\google_agents_orchestrator_results_20251128_024135.json
2025-11-28 02:41:35,856 [INFO] __main__: Saving results to MongoDB...
2025-11-28 02:41:36,400 [INFO] mongodb_integration: ✅ Successfully connected to MongoDB
2025-11-28 02:41:36,474 [INFO] mongodb_integration: ✅ Database indexes created successfully
2025-11-28 02:41:36,474 [INFO] mongodb_integration: ✅ MongoDB collections setup completed
2025-11-28 02:41:36,484 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024011_250154_e3db1142
2025-11-28 02:41:36,497 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024011_250154_a6e88460
2025-11-28 02:41:36,507 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024011_250154_21e732d6
2025-11-28 02:41:36,519 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024011_255364_5829a818
2025-11-28 02:41:36,531 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024011_255364_c6016002
2025-11-28 02:41:36,540 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024011_256759_9ef04c10
2025-11-28 02:41:36,551 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024011_256759_e2d6e199
2025-11-28 02:41:36,560 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024011_257943_210a3209
2025-11-28 02:41:36,570 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024011_257943_03196b85
2025-11-28 02:41:36,580 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024011_257943_9d2d57af
2025-11-28 02:41:36,588 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024027_830772_036e4eaa
2025-11-28 02:41:36,599 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024027_830772_ef492875
2025-11-28 02:41:36,606 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024027_834600_77128b92
2025-11-28 02:41:36,616 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024027_834600_6bf04d16
2025-11-28 02:41:36,626 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024027_834600_a5ce1e83
2025-11-28 02:41:36,637 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024027_836758_40854a8d
2025-11-28 02:41:36,641 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024027_838007_82e881e8
2025-11-28 02:41:36,655 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024027_838007_b8f1205c
2025-11-28 02:41:36,664 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024027_838007_4a4f9dc9
2025-11-28 02:41:36,669 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024027_840504_540b0cc7
2025-11-28 02:41:36,682 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024051_900818_6ca841ac
2025-11-28 02:41:36,690 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024051_900818_d57e76cb
2025-11-28 02:41:36,700 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024051_900818_b3c74691
2025-11-28 02:41:36,711 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024051_900818_4c24bda1
2025-11-28 02:41:36,719 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024051_900818_5c92ba20
2025-11-28 02:41:36,730 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024051_912022_e2b510f3
2025-11-28 02:41:36,740 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024051_912022_df07786a
2025-11-28 02:41:36,744 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024051_912022_cf524154
2025-11-28 02:41:36,752 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024051_912022_097585bf
2025-11-28 02:41:36,766 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024051_912022_12382e8f
2025-11-28 02:41:36,776 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024126_245943_e5dd7e73
2025-11-28 02:41:36,786 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024126_247500_8122540e
2025-11-28 02:41:36,793 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024126_248023_74bd4276
2025-11-28 02:41:36,800 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024126_248574_8c218448
2025-11-28 02:41:36,814 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024126_249621_eaa42678
2025-11-28 02:41:36,824 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024126_250129_2830279b
2025-11-28 02:41:36,830 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024126_250677_28e617c9
2025-11-28 02:41:36,845 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024126_251727_74fa81c8
2025-11-28 02:41:36,850 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024126_252332_0e1560cb
2025-11-28 02:41:36,863 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024126_252332_74d2e12f
2025-11-28 02:41:36,872 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024135_833135_970c038b
2025-11-28 02:41:36,881 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_024135_833135_8b3f8408
2025-11-28 02:41:36,881 [INFO] mongodb_integration: 📊 Debunk posts storage completed: 42 stored, 0 skipped, 0 errors
2025-11-28 02:41:36,881 [INFO] __main__: ✅ Successfully stored 42 debunk posts to MongoDB
2025-11-28 02:41:36,885 [INFO] mongodb_integration: 🔌 MongoDB connection closed
2025-11-28 02:41:36,916 [INFO] __main__: Google Agents orchestrated pipeline with batch processing completed successfully
2025-11-28 03:46:15,796 [INFO] __main__: Orchestrator Agent initialized with Google Agents SDK - Session: orchestrator_session_20251128_034615
2025-11-28 03:46:15,796 [INFO] __main__: Initializing Google Agents Orchestrator...
2025-11-28 03:46:15,796 [INFO] __main__: Google Agents Orchestrator initialized successfully
2025-11-28 03:46:15,796 [INFO] __main__: Initializing Claim Verifier with Google Agents...
2025-11-28 03:46:15,796 [INFO] claim_verifier.agents: Google Agents Orchestrator initialized successfully
2025-11-28 03:46:15,796 [INFO] claim_verifier.agents: Created Google Agent: claim_extractor - Claim Extraction Specialist
2025-11-28 03:46:15,796 [INFO] claim_verifier.agents: Created Google Agent: fact_verifier - Fact Verification Specialist
2025-11-28 03:46:15,796 [INFO] claim_verifier.agents: Created Google Agent: priority_assessor - Priority Assessment Specialist
2025-11-28 03:46:15,796 [INFO] claim_verifier.agents: Created Google Agent: report_generator - Report Generation Specialist
2025-11-28 03:46:15,796 [INFO] claim_verifier.agents: Claim verification agents setup completed with Google Agents SDK
2025-11-28 03:46:15,796 [INFO] claim_verifier.agents: Claim Verifier Orchestrator initialized with Google Agents SDK
2025-11-28 03:46:15,801 [INFO] __main__: Initializing Explanation Agent with Google Agents...
2025-11-28 03:46:15,801 [INFO] explanation_agent.agents: Google Agents Orchestrator initialized for Explanation Agent
2025-11-28 03:46:15,801 [INFO] explanation_agent.agents: Created Google Agent: content_generator - Content Generation Specialist
2025-11-28 03:46:15,801 [INFO] explanation_agent.agents: Created Google Agent: source_analyzer - Source Analysis Specialist
2025-11-28 03:46:15,801 [INFO] explanation_agent.agents: Created Google Agent: post_formatter - Post Formatting Specialist
2025-11-28 03:46:15,801 [INFO] explanation_agent.agents: Google Agents setup completed for explanation workflow
2025-11-28 03:46:15,803 [INFO] explanation_agent.agents: Explanation Agent initialized with Google Agents SDK
2025-11-28 03:46:15,804 [INFO] __main__: Created Google Agent: trend_scanner - Trend Scanning Coordinator
2025-11-28 03:46:15,807 [INFO] __main__: Created Google Agent: verifier_coordinator - Claim Verification Coordinator
2025-11-28 03:46:15,812 [INFO] __main__: Created Google Agent: explanation_coordinator - Explanation Generation Coordinator
2025-11-28 03:46:15,812 [INFO] __main__: Created Google Agent: results_integrator - Results Integration Specialist
2025-11-28 03:46:15,812 [INFO] __main__: Orchestrator agents setup completed with Google Agents SDK
2025-11-28 03:46:15,814 [INFO] __main__: Orchestrator Agent fully initialized with Google Agents SDK
2025-11-28 03:46:15,816 [INFO] __main__: Starting Google Agents orchestrated pipeline: Trend Scanning → Claim Verification
2025-11-28 03:46:15,816 [INFO] __main__: Step 1: Executing trend scanning with Google Agents...
2025-11-28 03:46:15,817 [INFO] __main__: Starting Google Agents workflow with 1 tasks
2025-11-28 03:46:15,818 [INFO] __main__: Executing task 1/1: trend_scanner - Execute comprehensive Reddit trend scanning with AI summarization and claim extraction
2025-11-28 03:46:15,818 [INFO] __main__: Agent Trend Scanning Coordinator has 1 tools available
2025-11-28 03:46:15,818 [INFO] __main__: Tool 0: <class 'function'> with methods: []...
2025-11-28 03:46:15,818 [INFO] __main__: Starting tool detection for task: 'Execute comprehensive Reddit trend scanning with AI summarization and claim extraction'
2025-11-28 03:46:15,818 [INFO] __main__: Checking conditions:
2025-11-28 03:46:15,818 [INFO] __main__:   - hasattr(tool, '__call__'): True
2025-11-28 03:46:15,818 [INFO] __main__:   - 'scan' in task_description.lower(): True
2025-11-28 03:46:15,818 [INFO] __main__:   - hasattr(tool, 'verify_content'): False
2025-11-28 03:46:15,818 [INFO] __main__:   - 'verify' in task_description.lower(): False
2025-11-28 03:46:15,821 [INFO] __main__:   - hasattr(tool, 'execute_workflow'): False
2025-11-28 03:46:15,821 [INFO] __main__:   - hasattr(tool, 'batch_create_posts'): False
2025-11-28 03:46:15,821 [INFO] __main__:   - 'explanation' in task_description.lower(): False
2025-11-28 03:46:15,823 [INFO] __main__:   - hasattr(tool, 'create_debunk_post'): False
2025-11-28 03:46:15,823 [INFO] __main__: Agent Trend Scanning Coordinator executing trend scanning tool...
2025-11-28 03:46:15,846 [INFO] trend_scanner.google_agents: Google Agents orchestration initialized successfully
2025-11-28 03:46:20,736 [INFO] trend_scanner.google_agents: PRAW Reddit client authenticated successfully
2025-11-28 03:46:26,484 [INFO] trend_scanner.tools.reddit_scan_tool: Google Agents SDK initialized successfully
2025-11-28 03:46:26,484 [INFO] trend_scanner.tools.twitter_scan_tool: Google Agents SDK initialized for Twitter scanner
2025-11-28 03:46:26,484 [INFO] trend_scanner.google_agents: Twitter scanner initialized successfully
2025-11-28 03:46:26,484 [INFO] trend_scanner.google_agents: Created Google Agent: reddit_scanner - Enhanced Reddit Trend Scout
2025-11-28 03:46:26,484 [INFO] trend_scanner.google_agents: Created Google Agent: twitter_scanner - Twitter/X Trend Scout
2025-11-28 03:46:26,484 [INFO] trend_scanner.google_agents: Created Google Agent: risk_assessor - Cross-Platform Content Risk Assessor
2025-11-28 03:46:26,484 [INFO] trend_scanner.google_agents: Google agents created for platforms: Reddit, Twitter
2025-11-28 03:46:26,484 [INFO] trend_scanner.google_agents: Target subreddits configured: []
2025-11-28 03:46:26,484 [INFO] trend_scanner.google_agents: Target Twitter configured: 3 accounts, AUTO-DISCOVER trending topics, scan_type=both
2025-11-28 03:46:26,484 [INFO] trend_scanner.google_agents: Starting multi-platform trend scanning (Twitter/both)...
2025-11-28 03:46:26,484 [INFO] trend_scanner.google_agents: Created Google Agent: reddit_scanner - Reddit Trend Scout
2025-11-28 03:46:26,484 [INFO] trend_scanner.google_agents: Created Google Agent: twitter_scanner - Twitter/X Trend Scout
2025-11-28 03:46:26,484 [INFO] trend_scanner.google_agents: Created Google Agent: risk_assessor - Cross-Platform Content Risk Assessor
2025-11-28 03:46:26,484 [INFO] trend_scanner.google_agents: Auto-discovering Twitter trending topics...
2025-11-28 03:46:27,997 [INFO] trend_scanner.tools.twitter_scan_tool: Loading cookies from twitter_cookies.json
2025-11-28 03:46:27,999 [INFO] trend_scanner.tools.twitter_scan_tool: Twitter client authenticated from cookies
2025-11-28 03:46:27,999 [INFO] trend_scanner.tools.twitter_scan_tool: Fetching Twitter trending topics...
2025-11-28 03:46:29,706 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Thanksgiving
2025-11-28 03:46:29,712 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: #StrangerThings5
2025-11-28 03:46:29,712 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: #HBDUdhay
2025-11-28 03:46:29,712 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: #WPLAuction
2025-11-28 03:46:29,712 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: #चतुर्थ_श्रेणी_पद_70K_करो
2025-11-28 03:46:29,712 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: #rapidoride
2025-11-28 03:46:29,713 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: AUKAAT KE BAHAR TRAILER OUT
2025-11-28 03:46:29,713 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Hindu Sanskriti
2025-11-28 03:46:29,713 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Sanatan Dharma Ki Mahima
2025-11-28 03:46:29,713 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: UP Warriorz
2025-11-28 03:46:29,713 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: KICK ASHNOOR OUT BB19
2025-11-28 03:46:29,713 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: हरिवंश राय बच्चन
2025-11-28 03:46:29,713 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: A. 5000mAh
2025-11-28 03:46:29,713 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: B. Panda Glass
2025-11-28 03:46:29,713 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: byers
2025-11-28 03:46:29,713 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Deepti Sharma
2025-11-28 03:46:29,713 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: I VOTED FOR SHEHBAAZ
2025-11-28 03:46:29,713 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Lauren Bell
2025-11-28 03:46:29,713 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: इमरान खान
2025-11-28 03:46:29,713 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: DYTD TRAILER
2025-11-28 03:46:29,720 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Gujarat Giants
2025-11-28 03:46:29,720 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Ranchi
2025-11-28 03:46:29,721 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: B. 33W
2025-11-28 03:46:29,721 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: संतोष वर्मा
2025-11-28 03:46:29,721 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: B. 50MP
2025-11-28 03:46:29,727 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Grace Harris
2025-11-28 03:46:29,730 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: National Guard
2025-11-28 03:46:29,730 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Meg Lanning
2025-11-28 03:46:29,730 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: value education
2025-11-28 03:46:29,730 [INFO] trend_scanner.tools.twitter_scan_tool: Found trending topic: Healy
2025-11-28 03:46:29,730 [INFO] trend_scanner.tools.twitter_scan_tool: Successfully fetched 30 trending topics
2025-11-28 03:46:29,735 [INFO] trend_scanner.google_agents: Auto-discovered 30 trending topics: ['Thanksgiving', '#StrangerThings5', '#HBDUdhay', '#WPLAuction', '#चतुर्थ_श्रेणी_पद_70K_करो', '#rapidoride', 'AUKAAT KE BAHAR TRAILER OUT', 'Hindu Sanskriti', 'Sanatan Dharma Ki Mahima', 'UP Warriorz', 'KICK ASHNOOR OUT BB19', 'हरिवंश राय बच्चन', 'A. 5000mAh', 'B. Panda Glass', 'byers', 'Deepti Sharma', 'I VOTED FOR SHEHBAAZ', 'Lauren Bell', 'इमरान खान', 'DYTD TRAILER', 'Gujarat Giants', 'Ranchi', 'B. 33W', 'संतोष वर्मा', 'B. 50MP', 'Grace Harris', 'National Guard', 'Meg Lanning', 'value education', 'Healy']
2025-11-28 03:46:29,736 [INFO] trend_scanner.google_agents: Starting parallel scan across 0 subreddits, 33 Twitter targets
2025-11-28 03:46:29,736 [INFO] trend_scanner.google_agents: Starting parallel workflow with 33 tasks
2025-11-28 03:46:29,736 [INFO] trend_scanner.google_agents: Executing parallel task 1/33 with agent 'twitter_scanner'
2025-11-28 03:46:29,738 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for QudsNen (type: user)
2025-11-28 03:46:29,749 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=user, target=QudsNen, limit=50)
2025-11-28 03:46:30,470 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:46:30,470 [INFO] trend_scanner.tools.twitter_scan_tool: Fetching tweets from user: @QudsNen
2025-11-28 03:46:32,362 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 14 tweets from @QudsNen
2025-11-28 03:46:32,362 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 12 tweets
2025-11-28 03:46:32,379 [INFO] LiteLLM: 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2025-11-28 03:46:55,176 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 03:46:55,183 [INFO] trend_scanner.tools.twitter_scan_tool: Batch risk assessment completed for 12 tweets
2025-11-28 03:46:55,183 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 12 tweets in 1 API call
2025-11-28 03:46:55,183 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned QudsNen (14 tweets, type=user), scraped 0 links, found 2 trending tweets
2025-11-28 03:46:55,189 [INFO] trend_scanner.google_agents: Executing parallel task 2/33 with agent 'twitter_scanner'
2025-11-28 03:46:55,193 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for NupurSharmaBJP (type: user)
2025-11-28 03:46:55,196 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=user, target=NupurSharmaBJP, limit=50)
2025-11-28 03:46:56,027 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:46:56,027 [INFO] trend_scanner.tools.twitter_scan_tool: Fetching tweets from user: @NupurSharmaBJP
2025-11-28 03:46:58,715 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from @NupurSharmaBJP
2025-11-28 03:46:58,715 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:46:58,715 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:46:58,715 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned NupurSharmaBJP (20 tweets, type=user), scraped 0 links, found 0 trending tweets
2025-11-28 03:46:58,715 [INFO] trend_scanner.google_agents: Executing parallel task 3/33 with agent 'twitter_scanner'
2025-11-28 03:46:58,719 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for IndianGems_ (type: user)
2025-11-28 03:46:58,721 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=user, target=IndianGems_, limit=50)
2025-11-28 03:46:59,586 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:46:59,586 [INFO] trend_scanner.tools.twitter_scan_tool: Fetching tweets from user: @IndianGems_
2025-11-28 03:47:01,534 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 19 tweets from @IndianGems_
2025-11-28 03:47:01,535 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 10 tweets
2025-11-28 03:47:01,537 [INFO] LiteLLM: 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2025-11-28 03:47:15,350 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 03:47:15,350 [INFO] trend_scanner.tools.twitter_scan_tool: Batch risk assessment completed for 10 tweets
2025-11-28 03:47:15,355 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 10 tweets in 1 API call
2025-11-28 03:47:15,355 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned IndianGems_ (19 tweets, type=user), scraped 0 links, found 2 trending tweets
2025-11-28 03:47:15,357 [INFO] trend_scanner.google_agents: Executing parallel task 4/33 with agent 'twitter_scanner'
2025-11-28 03:47:15,357 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Thanksgiving (type: trending)
2025-11-28 03:47:15,361 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Thanksgiving, limit=50)
2025-11-28 03:47:16,200 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:16,200 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Thanksgiving
2025-11-28 03:47:18,126 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from search (limited to 50)
2025-11-28 03:47:18,127 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:47:18,129 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:47:18,129 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned Thanksgiving (20 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:47:18,130 [INFO] trend_scanner.google_agents: Executing parallel task 5/33 with agent 'twitter_scanner'
2025-11-28 03:47:18,131 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for #StrangerThings5 (type: trending)
2025-11-28 03:47:18,135 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=#StrangerThings5, limit=50)
2025-11-28 03:47:18,980 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:18,980 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: #StrangerThings5
2025-11-28 03:47:21,087 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from search (limited to 50)
2025-11-28 03:47:21,087 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:47:21,087 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:47:21,087 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned #StrangerThings5 (20 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:47:21,090 [INFO] trend_scanner.google_agents: Executing parallel task 6/33 with agent 'twitter_scanner'
2025-11-28 03:47:21,091 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for #HBDUdhay (type: trending)
2025-11-28 03:47:21,095 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=#HBDUdhay, limit=50)
2025-11-28 03:47:21,972 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:21,972 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: #HBDUdhay
2025-11-28 03:47:23,533 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 3 tweets from search (limited to 50)
2025-11-28 03:47:23,533 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:47:23,533 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:47:23,533 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned #HBDUdhay (3 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:47:23,543 [INFO] trend_scanner.google_agents: Executing parallel task 7/33 with agent 'twitter_scanner'
2025-11-28 03:47:23,543 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for #WPLAuction (type: trending)
2025-11-28 03:47:23,543 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=#WPLAuction, limit=50)
2025-11-28 03:47:24,430 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:24,430 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: #WPLAuction
2025-11-28 03:47:25,312 [WARNING] trend_scanner.tools.twitter_scan_tool: Twitter returned 404 Not Found for search '#WPLAuction' - no results available
2025-11-28 03:47:25,312 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: #WPLAuction
2025-11-28 03:47:25,312 [INFO] trend_scanner.google_agents: Executing parallel task 8/33 with agent 'twitter_scanner'
2025-11-28 03:47:25,314 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for #चतुर्थ_श्रेणी_पद_70K_करो (type: trending)
2025-11-28 03:47:25,314 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=#चतुर्थ_श्रेणी_पद_70K_करो, limit=50)
2025-11-28 03:47:26,145 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:26,145 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: #चतुर्थ_श्रेणी_पद_70K_करो
2025-11-28 03:47:28,201 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 11 tweets from search (limited to 50)
2025-11-28 03:47:28,201 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:47:28,201 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:47:28,201 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned #चतुर्थ_श्रेणी_पद_70K_करो (11 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:47:28,201 [INFO] trend_scanner.google_agents: Executing parallel task 9/33 with agent 'twitter_scanner'
2025-11-28 03:47:28,210 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for #rapidoride (type: trending)
2025-11-28 03:47:28,212 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=#rapidoride, limit=50)
2025-11-28 03:47:29,046 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:29,046 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: #rapidoride
2025-11-28 03:47:30,711 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 17 tweets from search (limited to 50)
2025-11-28 03:47:30,713 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:47:30,713 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:47:30,713 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned #rapidoride (17 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:47:30,713 [INFO] trend_scanner.google_agents: Executing parallel task 10/33 with agent 'twitter_scanner'
2025-11-28 03:47:30,716 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for AUKAAT KE BAHAR TRAILER OUT (type: trending)
2025-11-28 03:47:30,721 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=AUKAAT KE BAHAR TRAILER OUT, limit=50)
2025-11-28 03:47:31,641 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:31,641 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: AUKAAT KE BAHAR TRAILER OUT
2025-11-28 03:47:33,580 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from search (limited to 50)
2025-11-28 03:47:33,580 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:47:33,582 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:47:33,582 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned AUKAAT KE BAHAR TRAILER OUT (20 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:47:33,584 [INFO] trend_scanner.google_agents: Executing parallel task 11/33 with agent 'twitter_scanner'
2025-11-28 03:47:33,584 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Hindu Sanskriti (type: trending)
2025-11-28 03:47:33,587 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Hindu Sanskriti, limit=50)
2025-11-28 03:47:34,405 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:34,405 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Hindu Sanskriti
2025-11-28 03:47:35,959 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 9 tweets from search (limited to 50)
2025-11-28 03:47:35,960 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:47:35,960 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:47:35,961 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned Hindu Sanskriti (9 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:47:35,962 [INFO] trend_scanner.google_agents: Executing parallel task 12/33 with agent 'twitter_scanner'
2025-11-28 03:47:35,962 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Sanatan Dharma Ki Mahima (type: trending)
2025-11-28 03:47:35,965 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Sanatan Dharma Ki Mahima, limit=50)
2025-11-28 03:47:36,744 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:36,744 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Sanatan Dharma Ki Mahima
2025-11-28 03:47:38,594 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 5 tweets from search (limited to 50)
2025-11-28 03:47:38,594 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:47:38,594 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:47:38,597 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned Sanatan Dharma Ki Mahima (5 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:47:38,597 [INFO] trend_scanner.google_agents: Executing parallel task 13/33 with agent 'twitter_scanner'
2025-11-28 03:47:38,597 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for UP Warriorz (type: trending)
2025-11-28 03:47:38,599 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=UP Warriorz, limit=50)
2025-11-28 03:47:39,458 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:39,462 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: UP Warriorz
2025-11-28 03:47:41,977 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 17 tweets from search (limited to 50)
2025-11-28 03:47:41,977 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:47:41,980 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:47:41,980 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned UP Warriorz (17 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:47:41,980 [INFO] trend_scanner.google_agents: Executing parallel task 14/33 with agent 'twitter_scanner'
2025-11-28 03:47:41,980 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for KICK ASHNOOR OUT BB19 (type: trending)
2025-11-28 03:47:41,984 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=KICK ASHNOOR OUT BB19, limit=50)
2025-11-28 03:47:42,878 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:42,878 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: KICK ASHNOOR OUT BB19
2025-11-28 03:47:44,435 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 4 tweets from search (limited to 50)
2025-11-28 03:47:44,435 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:47:44,435 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:47:44,435 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned KICK ASHNOOR OUT BB19 (4 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:47:44,437 [INFO] trend_scanner.google_agents: Executing parallel task 15/33 with agent 'twitter_scanner'
2025-11-28 03:47:44,437 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for हरिवंश राय बच्चन (type: trending)
2025-11-28 03:47:44,439 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=हरिवंश राय बच्चन, limit=50)
2025-11-28 03:47:45,312 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:45,312 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: हरिवंश राय बच्चन
2025-11-28 03:47:46,933 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from search (limited to 50)
2025-11-28 03:47:46,933 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 1 tweets
2025-11-28 03:47:46,933 [INFO] LiteLLM: 
LiteLLM completion() model= gemini-2.5-flash; provider = gemini
2025-11-28 03:47:50,829 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 03:47:50,832 [INFO] trend_scanner.tools.twitter_scan_tool: Batch risk assessment completed for 1 tweets
2025-11-28 03:47:50,833 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 1 tweets in 1 API call
2025-11-28 03:47:50,834 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned हरिवंश राय बच्चन (20 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:47:50,834 [INFO] trend_scanner.google_agents: Executing parallel task 16/33 with agent 'twitter_scanner'
2025-11-28 03:47:50,836 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for A. 5000mAh (type: trending)
2025-11-28 03:47:50,839 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=A. 5000mAh, limit=50)
2025-11-28 03:47:51,687 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:51,687 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: A. 5000mAh
2025-11-28 03:47:53,064 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 18 tweets from search (limited to 50)
2025-11-28 03:47:53,068 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:47:53,068 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:47:53,068 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned A. 5000mAh (18 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:47:53,068 [INFO] trend_scanner.google_agents: Executing parallel task 17/33 with agent 'twitter_scanner'
2025-11-28 03:47:53,068 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for B. Panda Glass (type: trending)
2025-11-28 03:47:53,071 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=B. Panda Glass, limit=50)
2025-11-28 03:47:53,961 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:53,961 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: B. Panda Glass
2025-11-28 03:47:55,280 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 16 tweets from search (limited to 50)
2025-11-28 03:47:55,280 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:47:55,280 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:47:55,280 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned B. Panda Glass (16 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:47:55,280 [INFO] trend_scanner.google_agents: Executing parallel task 18/33 with agent 'twitter_scanner'
2025-11-28 03:47:55,280 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for byers (type: trending)
2025-11-28 03:47:55,292 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=byers, limit=50)
2025-11-28 03:47:56,136 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:56,136 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: byers
2025-11-28 03:47:57,231 [WARNING] trend_scanner.tools.twitter_scan_tool: Twitter returned 404 Not Found for search 'byers' - no results available
2025-11-28 03:47:57,231 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: byers
2025-11-28 03:47:57,231 [INFO] trend_scanner.google_agents: Executing parallel task 19/33 with agent 'twitter_scanner'
2025-11-28 03:47:57,231 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Deepti Sharma (type: trending)
2025-11-28 03:47:57,231 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Deepti Sharma, limit=50)
2025-11-28 03:47:58,062 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:47:58,062 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Deepti Sharma
2025-11-28 03:47:59,382 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 15 tweets from search (limited to 50)
2025-11-28 03:47:59,382 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:47:59,382 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:47:59,382 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned Deepti Sharma (15 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:47:59,382 [INFO] trend_scanner.google_agents: Executing parallel task 20/33 with agent 'twitter_scanner'
2025-11-28 03:47:59,382 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for I VOTED FOR SHEHBAAZ (type: trending)
2025-11-28 03:47:59,382 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=I VOTED FOR SHEHBAAZ, limit=50)
2025-11-28 03:48:00,155 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:48:00,155 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: I VOTED FOR SHEHBAAZ
2025-11-28 03:48:01,730 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 0 tweets from search (limited to 50)
2025-11-28 03:48:01,730 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: I VOTED FOR SHEHBAAZ
2025-11-28 03:48:01,730 [INFO] trend_scanner.google_agents: Executing parallel task 21/33 with agent 'twitter_scanner'
2025-11-28 03:48:01,730 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Lauren Bell (type: trending)
2025-11-28 03:48:01,730 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Lauren Bell, limit=50)
2025-11-28 03:48:02,550 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:48:02,550 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Lauren Bell
2025-11-28 03:48:04,722 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from search (limited to 50)
2025-11-28 03:48:04,727 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:48:04,729 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:48:04,729 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned Lauren Bell (20 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:48:04,730 [INFO] trend_scanner.google_agents: Executing parallel task 22/33 with agent 'twitter_scanner'
2025-11-28 03:48:04,731 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for इमरान खान (type: trending)
2025-11-28 03:48:04,733 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=इमरान खान, limit=50)
2025-11-28 03:48:05,540 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:48:05,540 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: इमरान खान
2025-11-28 03:48:06,909 [WARNING] trend_scanner.tools.twitter_scan_tool: Twitter returned 404 Not Found for search 'इमरान खान' - no results available
2025-11-28 03:48:06,909 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: इमरान खान
2025-11-28 03:48:06,909 [INFO] trend_scanner.google_agents: Executing parallel task 23/33 with agent 'twitter_scanner'
2025-11-28 03:48:06,911 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for DYTD TRAILER (type: trending)
2025-11-28 03:48:06,913 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=DYTD TRAILER, limit=50)
2025-11-28 03:48:07,769 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:48:07,769 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: DYTD TRAILER
2025-11-28 03:48:09,626 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from search (limited to 50)
2025-11-28 03:48:09,628 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:48:09,630 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:48:09,630 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned DYTD TRAILER (20 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:48:09,631 [INFO] trend_scanner.google_agents: Executing parallel task 24/33 with agent 'twitter_scanner'
2025-11-28 03:48:09,638 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Gujarat Giants (type: trending)
2025-11-28 03:48:09,645 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Gujarat Giants, limit=50)
2025-11-28 03:48:10,590 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:48:10,600 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Gujarat Giants
2025-11-28 03:48:12,082 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from search (limited to 50)
2025-11-28 03:48:12,084 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:48:12,084 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:48:12,085 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned Gujarat Giants (20 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:48:12,085 [INFO] trend_scanner.google_agents: Executing parallel task 25/33 with agent 'twitter_scanner'
2025-11-28 03:48:12,087 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Ranchi (type: trending)
2025-11-28 03:48:12,088 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Ranchi, limit=50)
2025-11-28 03:48:12,900 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:48:12,900 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Ranchi
2025-11-28 03:48:14,228 [WARNING] trend_scanner.tools.twitter_scan_tool: Twitter returned 404 Not Found for search 'Ranchi' - no results available
2025-11-28 03:48:14,229 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: Ranchi
2025-11-28 03:48:14,231 [INFO] trend_scanner.google_agents: Executing parallel task 26/33 with agent 'twitter_scanner'
2025-11-28 03:48:14,231 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for B. 33W (type: trending)
2025-11-28 03:48:14,232 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=B. 33W, limit=50)
2025-11-28 03:48:15,092 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:48:15,093 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: B. 33W
2025-11-28 03:48:16,104 [WARNING] trend_scanner.tools.twitter_scan_tool: Twitter returned 404 Not Found for search 'B. 33W' - no results available
2025-11-28 03:48:16,104 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: B. 33W
2025-11-28 03:48:16,104 [INFO] trend_scanner.google_agents: Executing parallel task 27/33 with agent 'twitter_scanner'
2025-11-28 03:48:16,104 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for संतोष वर्मा (type: trending)
2025-11-28 03:48:16,107 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=संतोष वर्मा, limit=50)
2025-11-28 03:48:17,005 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:48:17,005 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: संतोष वर्मा
2025-11-28 03:48:19,250 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from search (limited to 50)
2025-11-28 03:48:19,250 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:48:19,253 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:48:19,253 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned संतोष वर्मा (20 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:48:19,254 [INFO] trend_scanner.google_agents: Executing parallel task 28/33 with agent 'twitter_scanner'
2025-11-28 03:48:19,254 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for B. 50MP (type: trending)
2025-11-28 03:48:19,254 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=B. 50MP, limit=50)
2025-11-28 03:48:20,078 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:48:20,078 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: B. 50MP
2025-11-28 03:48:21,830 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 15 tweets from search (limited to 50)
2025-11-28 03:48:21,833 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:48:21,845 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:48:21,845 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned B. 50MP (15 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:48:21,848 [INFO] trend_scanner.google_agents: Executing parallel task 29/33 with agent 'twitter_scanner'
2025-11-28 03:48:21,852 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Grace Harris (type: trending)
2025-11-28 03:48:21,879 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Grace Harris, limit=50)
2025-11-28 03:48:22,704 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:48:22,706 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Grace Harris
2025-11-28 03:48:24,307 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from search (limited to 50)
2025-11-28 03:48:24,307 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:48:24,307 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:48:24,307 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned Grace Harris (20 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:48:24,307 [INFO] trend_scanner.google_agents: Executing parallel task 30/33 with agent 'twitter_scanner'
2025-11-28 03:48:24,307 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for National Guard (type: trending)
2025-11-28 03:48:24,313 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=National Guard, limit=50)
2025-11-28 03:48:25,098 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:48:25,098 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: National Guard
2025-11-28 03:48:27,035 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 20 tweets from search (limited to 50)
2025-11-28 03:48:27,037 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:48:27,037 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:48:27,037 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned National Guard (20 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:48:27,037 [INFO] trend_scanner.google_agents: Executing parallel task 31/33 with agent 'twitter_scanner'
2025-11-28 03:48:27,039 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Meg Lanning (type: trending)
2025-11-28 03:48:27,040 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Meg Lanning, limit=50)
2025-11-28 03:48:27,877 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:48:27,877 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Meg Lanning
2025-11-28 03:48:29,900 [INFO] trend_scanner.tools.twitter_scan_tool: Fetched 19 tweets from search (limited to 50)
2025-11-28 03:48:29,900 [INFO] trend_scanner.tools.twitter_scan_tool: Performing batch risk assessment for 0 tweets
2025-11-28 03:48:29,903 [INFO] trend_scanner.tools.twitter_scan_tool: Batch processing: assessed 0 tweets in 1 API call
2025-11-28 03:48:29,903 [INFO] trend_scanner.tools.twitter_scan_tool: Scan summary: Scanned Meg Lanning (19 tweets, type=trending), scraped 0 links, found 0 trending tweets
2025-11-28 03:48:29,903 [INFO] trend_scanner.google_agents: Executing parallel task 32/33 with agent 'twitter_scanner'
2025-11-28 03:48:29,903 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for value education (type: trending)
2025-11-28 03:48:29,906 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=value education, limit=50)
2025-11-28 03:48:30,928 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:48:30,929 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: value education
2025-11-28 03:48:32,250 [WARNING] trend_scanner.tools.twitter_scan_tool: Twitter returned 404 Not Found for search 'value education' - no results available
2025-11-28 03:48:32,250 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: value education
2025-11-28 03:48:32,250 [INFO] trend_scanner.google_agents: Executing parallel task 33/33 with agent 'twitter_scanner'
2025-11-28 03:48:32,250 [INFO] trend_scanner.google_agents: Agent Twitter/X Trend Scout executing Twitter scan for Healy (type: trending)
2025-11-28 03:48:32,250 [INFO] trend_scanner.tools.twitter_scan_tool: Starting Twitter scan (type=trending, target=Healy, limit=50)
2025-11-28 03:48:33,082 [INFO] trend_scanner.tools.twitter_scan_tool: Loaded cookies for fresh client
2025-11-28 03:48:33,082 [INFO] trend_scanner.tools.twitter_scan_tool: Searching tweets for: Healy
2025-11-28 03:48:34,504 [WARNING] trend_scanner.tools.twitter_scan_tool: Twitter returned 404 Not Found for search 'Healy' - no results available
2025-11-28 03:48:34,506 [WARNING] trend_scanner.tools.twitter_scan_tool: No tweets found for target: Healy
2025-11-28 03:48:42,595 [INFO] trend_scanner.google_agents: Executing cross-platform risk assessment
2025-11-28 03:49:47,102 [INFO] trend_scanner.google_agents: Content Risk Assessor provided with 4 posts from multiple platforms for cross-platform analysis
2025-11-28 03:49:59,053 [INFO] trend_scanner.google_agents: Processed Twitter scan: 2 posts
2025-11-28 03:49:59,053 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,053 [INFO] trend_scanner.google_agents: Processed Twitter scan: 2 posts
2025-11-28 03:49:59,053 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,053 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,059 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,059 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,059 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,059 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,059 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,059 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,059 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,059 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,059 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,059 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,059 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,059 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,062 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,062 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,062 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,062 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,062 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,062 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,062 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,062 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,062 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,064 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,064 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,064 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,064 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,065 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,065 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,065 [INFO] trend_scanner.google_agents: Processed Twitter scan: 0 posts
2025-11-28 03:49:59,065 [INFO] trend_scanner.google_agents: Multi-platform scan completed - Reddit: 0, Threads: 0, Telegram: 0, Twitter: 4, Total: 4
2025-11-28 03:50:04,934 [INFO] __main__: Workflow completed: 1/1 tasks successful
2025-11-28 03:50:04,935 [INFO] __main__: Found 4 posts from trend scanner, preparing for verification...
2025-11-28 03:50:04,935 [INFO] __main__: Prepared 4 claims for verification
2025-11-28 03:50:04,935 [INFO] __main__: Step 2: Executing claim verification with batch processing...
2025-11-28 03:50:04,935 [INFO] __main__: Starting Google Agents workflow with 1 tasks
2025-11-28 03:50:04,935 [INFO] __main__: Executing task 1/1: verifier_coordinator - Verify extracted claims using comprehensive fact-checking workflow
2025-11-28 03:50:04,935 [INFO] __main__: Agent Claim Verification Coordinator has 1 tools available
2025-11-28 03:50:04,935 [INFO] __main__: Tool 0: <class 'claim_verifier.agents.ClaimVerifierOrchestrator'> with methods: ['claim_extractor', 'fact_checker', 'fact_verifier', 'gemini_api_key', 'google_agents', 'priority_assessor', 'quick_verify', 'report_generator', 'verify_content']...
2025-11-28 03:50:04,935 [INFO] __main__: Starting tool detection for task: 'Verify extracted claims using comprehensive fact-checking workflow'
2025-11-28 03:50:04,935 [INFO] __main__: Checking conditions:
2025-11-28 03:50:04,935 [INFO] __main__:   - hasattr(tool, '__call__'): False
2025-11-28 03:50:04,935 [INFO] __main__:   - 'scan' in task_description.lower(): False
2025-11-28 03:50:04,935 [INFO] __main__:   - hasattr(tool, 'verify_content'): True
2025-11-28 03:50:04,935 [INFO] __main__:   - 'verify' in task_description.lower(): True
2025-11-28 03:50:04,935 [INFO] __main__:   - hasattr(tool, 'execute_workflow'): False
2025-11-28 03:50:04,935 [INFO] __main__:   - hasattr(tool, 'batch_create_posts'): False
2025-11-28 03:50:04,935 [INFO] __main__:   - 'explanation' in task_description.lower(): False
2025-11-28 03:50:04,935 [INFO] __main__:   - hasattr(tool, 'create_debunk_post'): False
2025-11-28 03:50:04,935 [INFO] __main__: Agent Claim Verification Coordinator executing claim verification tool with batch processing...
2025-11-28 03:50:04,935 [INFO] __main__: Processing 4 claims using batch verification...
2025-11-28 03:50:04,935 [INFO] claim_verifier.agents: Starting Google Agents claim verification for 4 content items with batch processing
2025-11-28 03:50:04,935 [INFO] claim_verifier.agents: Processing 4 claims in batches of 15
2025-11-28 03:50:04,935 [INFO] claim_verifier.agents: Processing batch 1: claims 1-4
2025-11-28 03:50:30,519 [INFO] claim_verifier.agents: Batch verification completed: 4 total claims processed
2025-11-28 03:50:30,523 [INFO] __main__: Workflow completed: 1/1 tasks successful
2025-11-28 03:50:30,523 [INFO] __main__: Extracted 4 verified claims for explanation generation
2025-11-28 03:50:30,523 [INFO] __main__: Processing 4 verified claims for explanation generation
2025-11-28 03:50:30,523 [INFO] __main__: Claim 0: verdict='false', verified=False, claim_text='Israel's National Security Minister praised Israel...'
2025-11-28 03:50:30,523 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 03:50:30,526 [INFO] __main__:   Found 5 source links and 5 source titles
2025-11-28 03:50:30,526 [INFO] __main__: ✅ INCLUDING claim for debunk post: Israel's National Security Minister praised Israel... (verdict: false)
2025-11-28 03:50:30,526 [INFO] __main__:   Sources included: 5 links
2025-11-28 03:50:30,526 [INFO] __main__: Claim 1: verdict='mixed', verified=False, claim_text='Nurse Tasneem Al-Hams was abducted, incarcerated, ...'
2025-11-28 03:50:30,526 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 03:50:30,527 [INFO] __main__:   Found 2 source links and 2 source titles
2025-11-28 03:50:30,527 [INFO] __main__: ✅ INCLUDING claim for debunk post: Nurse Tasneem Al-Hams was abducted, incarcerated, ... (verdict: mixed)
2025-11-28 03:50:30,527 [INFO] __main__:   Sources included: 2 links
2025-11-28 03:50:30,527 [INFO] __main__: Claim 2: verdict='uncertain', verified=False, claim_text='High taxes in a country do not guarantee public sa...'
2025-11-28 03:50:30,527 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 03:50:30,527 [INFO] __main__:   Found 3 source links and 3 source titles
2025-11-28 03:50:30,527 [INFO] __main__: ✅ INCLUDING claim for debunk post: High taxes in a country do not guarantee public sa... (verdict: uncertain)
2025-11-28 03:50:30,528 [INFO] __main__:   Sources included: 3 links
2025-11-28 03:50:30,528 [INFO] __main__: Claim 3: verdict='false', verified=False, claim_text='The post describes an ideal country free from corr...'
2025-11-28 03:50:30,528 [INFO] __main__:   Original claim structure keys: ['claim_text', 'content_summary', 'source', 'verification', 'claim_metadata', 'verification_timestamp']
2025-11-28 03:50:30,528 [INFO] __main__:   Found 5 source links and 5 source titles
2025-11-28 03:50:30,528 [INFO] __main__: ✅ INCLUDING claim for debunk post: The post describes an ideal country free from corr... (verdict: false)
2025-11-28 03:50:30,529 [INFO] __main__:   Sources included: 5 links
2025-11-28 03:50:30,529 [INFO] __main__: Verdict distribution: {'false': 2, 'mixed': 1, 'uncertain': 1}
2025-11-28 03:50:30,529 [INFO] __main__: Total claims for debunk posts: 4 out of 4
2025-11-28 03:50:30,529 [INFO] __main__: Step 3: Executing explanation generation with batch processing for 4 misinformation claims...
2025-11-28 03:50:30,529 [INFO] __main__: Starting Google Agents workflow with 1 tasks
2025-11-28 03:50:30,529 [INFO] __main__: Executing task 1/1: explanation_coordinator - Generate debunk posts for misinformation claims using batch processing
2025-11-28 03:50:30,531 [INFO] __main__: Agent Explanation Generation Coordinator has 1 tools available
2025-11-28 03:50:30,531 [INFO] __main__: Tool 0: <class 'explanation_agent.agents.ExplanationAgent'> with methods: ['batch_create_posts', 'content_generator', 'create_debunk_post', 'orchestrator', 'source_analyzer']...
2025-11-28 03:50:30,531 [INFO] __main__: Starting tool detection for task: 'Generate debunk posts for misinformation claims using batch processing'
2025-11-28 03:50:30,531 [INFO] __main__: Checking conditions:
2025-11-28 03:50:30,531 [INFO] __main__:   - hasattr(tool, '__call__'): False
2025-11-28 03:50:30,531 [INFO] __main__:   - 'scan' in task_description.lower(): False
2025-11-28 03:50:30,531 [INFO] __main__:   - hasattr(tool, 'verify_content'): False
2025-11-28 03:50:30,531 [INFO] __main__:   - 'verify' in task_description.lower(): False
2025-11-28 03:50:30,531 [INFO] __main__:   - hasattr(tool, 'execute_workflow'): False
2025-11-28 03:50:30,533 [INFO] __main__:   - hasattr(tool, 'batch_create_posts'): True
2025-11-28 03:50:30,533 [INFO] __main__:   - 'explanation' in task_description.lower(): False
2025-11-28 03:50:30,533 [INFO] __main__:   - hasattr(tool, 'create_debunk_post'): True
2025-11-28 03:50:30,533 [INFO] __main__: Agent Explanation Generation Coordinator executing ExplanationAgent with batch processing...
2025-11-28 03:50:30,533 [INFO] __main__: Tool type: <class 'explanation_agent.agents.ExplanationAgent'>
2025-11-28 03:50:30,533 [INFO] __main__: Tool methods: ['batch_create_posts', 'content_generator', 'create_debunk_post', 'orchestrator', 'source_analyzer']
2025-11-28 03:50:30,534 [INFO] __main__: Task description: 'Generate debunk posts for misinformation claims using batch processing'
2025-11-28 03:50:30,534 [INFO] __main__: Task description contains 'explanation': False
2025-11-28 03:50:30,534 [INFO] __main__: Tool has batch_create_posts: True
2025-11-28 03:50:30,534 [INFO] __main__: Received verification_results: 4 items
2025-11-28 03:50:30,534 [INFO] __main__: Found 4 verification results for explanation generation
2025-11-28 03:50:30,534 [INFO] __main__: Verification result 0: keys = ['claim_text', 'verification', 'sources', 'source', 'content_summary', 'verified', 'verdict']
2025-11-28 03:50:30,534 [INFO] __main__: Verification result 1: keys = ['claim_text', 'verification', 'sources', 'source', 'content_summary', 'verified', 'verdict']
2025-11-28 03:50:30,534 [INFO] __main__: Creating debunk posts for 4 claims using batch processing...
2025-11-28 03:50:30,536 [INFO] explanation_agent.agents: Creating 4 debunk posts with batch Google Agents processing...
2025-11-28 03:50:30,536 [INFO] explanation_agent.agents: Processing batch 1: posts 1-4
2025-11-28 03:50:30,536 [INFO] explanation_agent.agents: Agent Content Generation Specialist executing batch processing tool...
2025-11-28 03:50:47,726 [INFO] explanation_agent.agents: Raw Gemini response (first 500 chars): ```json
[
    {
        "heading": "No Evidence of Israeli Minister Praising West Bank Executions",
        "body": "The claim that Israel's National Security Minister praised Israeli forces for executing unarmed, detained Palestinians in the West Bank is false. Extensive searches of reputable news sources and official statements reveal no credible reports or evidence of any Israeli minister making such a statement. While the provided sources (Al Jazeera live blog and BBC news report) do cover I
2025-11-28 03:50:47,726 [INFO] explanation_agent.agents: Cleaned response (first 500 chars): [
    {
        "heading": "No Evidence of Israeli Minister Praising West Bank Executions",
        "body": "The claim that Israel's National Security Minister praised Israeli forces for executing unarmed, detained Palestinians in the West Bank is false. Extensive searches of reputable news sources and official statements reveal no credible reports or evidence of any Israeli minister making such a statement. While the provided sources (Al Jazeera live blog and BBC news report) do cover Israeli m
2025-11-28 03:50:47,726 [INFO] explanation_agent.agents: Extracted JSON: [
    {
        "heading": "No Evidence of Israeli Minister Praising West Bank Executions",
        "body": "The claim that Israel's National Security Minister praised Israeli forces for executing unarmed, detained Palestinians in the West Bank is false. Extensive searches of reputable news sources and official statements reveal no credible reports or evidence of any Israeli minister making such a statement. While the provided sources (Al Jazeera live blog and BBC news report) do cover Israeli m
2025-11-28 03:50:47,729 [INFO] explanation_agent.agents: Agent Source Analysis Specialist executing batch processing tool...
2025-11-28 03:50:47,729 [INFO] explanation_agent.agents: Processing batch sources for 4 verification results
2025-11-28 03:50:47,729 [INFO] explanation_agent.agents: Verification result 0: 5 links, 5 titles
2025-11-28 03:50:47,729 [INFO] explanation_agent.agents:   Links: ['https://www.aljazeera.com/news/liveblog/2025/11/27/live-israel-launches-air-strikes-on-west-bank-as-incursion-turns-deadly', 'https://www.bbc.com/news/world-middle-east-66582163']
2025-11-28 03:50:47,729 [INFO] explanation_agent.agents:   Titles: ['LIVE: Israel launches air strikes on West Bank as incursion turns ...', 'Palestinian militant, 17, killed during Israeli West Bank raid']
2025-11-28 03:50:47,731 [INFO] explanation_agent.agents: Verification result 0: Created 5 source entries
2025-11-28 03:50:47,731 [INFO] explanation_agent.agents: Verification result 1: 2 links, 2 titles
2025-11-28 03:50:47,731 [INFO] explanation_agent.agents:   Links: ['https://www.aljazeera.com/news/liveblog/2025/11/27/live-israel-launches-air-strikes-on-west-bank-as-incursion-turns-deadly', 'https://www.theguardian.com/world/2025/oct/03/egypt-foreign-minister-urges-hamas-to-accept-trump-gaza-plan-and-disarm']
2025-11-28 03:50:47,733 [INFO] explanation_agent.agents:   Titles: ['LIVE: Israel launches air strikes on West Bank as incursion turns ...', 'Egypt foreign minister urges Hamas to accept Trump Gaza plan and ...']
2025-11-28 03:50:47,733 [INFO] explanation_agent.agents: Verification result 1: Created 2 source entries
2025-11-28 03:50:47,734 [INFO] explanation_agent.agents: Verification result 2: 3 links, 3 titles
2025-11-28 03:50:47,734 [INFO] explanation_agent.agents:   Links: ['https://www.factcheck.org/2025/07/unraveling-the-big-beautiful-bill-spin/', 'https://www.pbs.org/newshour/show/gop-gives-ice-massive-budget-increase-to-expand-trumps-deportation-effort']
2025-11-28 03:50:47,734 [INFO] explanation_agent.agents:   Titles: ['Unraveling the Big Beautiful Bill Spin - FactCheck.org', "GOP gives ICE massive budget increase to expand Trump's ..."]
2025-11-28 03:50:47,735 [INFO] explanation_agent.agents: Verification result 2: Created 3 source entries
2025-11-28 03:50:47,735 [INFO] explanation_agent.agents: Verification result 3: 5 links, 5 titles
2025-11-28 03:50:47,735 [INFO] explanation_agent.agents:   Links: ['https://www.bbc.com/news/world-asia-india-37974423', 'https://www.theatlantic.com/ideas/archive/2025/02/corruption-trump-administration/681794/']
2025-11-28 03:50:47,735 [INFO] explanation_agent.agents:   Titles: ['Why India wiped out 86% of its cash overnight - BBC News', 'One Word Describes Trump - The Atlantic']
2025-11-28 03:50:47,735 [INFO] explanation_agent.agents: Verification result 3: Created 5 source entries
2025-11-28 03:50:47,735 [INFO] explanation_agent.agents: Batch source analysis completed: 19 total sources processed
2025-11-28 03:50:47,740 [INFO] explanation_agent.agents: Batch processing completed: 4 total posts created
2025-11-28 03:50:47,740 [INFO] __main__: Tool result type: <class 'dict'>
2025-11-28 03:50:47,743 [INFO] __main__: Tool result keys: ['success', 'message', 'debunk_posts', 'batch_statistics']
2025-11-28 03:50:47,745 [INFO] __main__: Batch explanation generation completed successfully with 4 posts generated
2025-11-28 03:50:47,745 [INFO] __main__: ExplanationAgent tool execution completed - tool_used: True
2025-11-28 03:50:47,746 [INFO] __main__: Workflow completed: 1/1 tasks successful
2025-11-28 03:50:47,747 [INFO] __main__: Explanation generation completed: True
2025-11-28 03:50:47,747 [INFO] __main__: Step 4: Processing and combining all results...
2025-11-28 03:50:47,747 [INFO] __main__: Trend scanning completed: 4 posts
2025-11-28 03:50:47,747 [INFO] __main__: Claim verification completed: True
2025-11-28 03:50:47,747 [INFO] __main__: Batch verification processed 4 claims in batches of 4
2025-11-28 03:50:47,747 [INFO] __main__: Explanation generation completed: True
2025-11-28 03:50:47,748 [INFO] __main__: Batch explanation generation processed 4 claims in batches of 4
2025-11-28 03:50:47,748 [INFO] __main__: Successfully created 4 debunk posts
2025-11-28 03:50:47,748 [INFO] __main__: Extracted 4 debunk posts from explanation generation
2025-11-28 03:50:47,758 [INFO] __main__: Google Agents results saved to: orchestrator_results\google_agents_orchestrator_results_20251128_035047.json
2025-11-28 03:50:47,759 [INFO] __main__: Saving results to MongoDB...
2025-11-28 03:50:48,362 [INFO] mongodb_integration: ✅ Successfully connected to MongoDB
2025-11-28 03:50:48,434 [INFO] mongodb_integration: ✅ Database indexes created successfully
2025-11-28 03:50:48,434 [INFO] mongodb_integration: ✅ MongoDB collections setup completed
2025-11-28 03:50:48,452 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_035047_735100_6944f266
2025-11-28 03:50:48,464 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_035047_735100_6a89b622
2025-11-28 03:50:48,478 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_035047_740054_31171bb9
2025-11-28 03:50:48,491 [INFO] mongodb_integration: ✅ Stored debunk post: aegis_post_20251128_035047_740699_a1e475b8
2025-11-28 03:50:48,491 [INFO] mongodb_integration: 📊 Debunk posts storage completed: 4 stored, 0 skipped, 0 errors
2025-11-28 03:50:48,492 [INFO] __main__: ✅ Successfully stored 4 debunk posts to MongoDB
2025-11-28 03:50:48,500 [INFO] mongodb_integration: 🔌 MongoDB connection closed
2025-11-28 03:50:48,507 [INFO] __main__: Google Agents orchestrated pipeline with batch processing completed successfully
